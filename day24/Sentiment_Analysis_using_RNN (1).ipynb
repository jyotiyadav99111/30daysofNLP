{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Sentiment_Analysis_using_RNN.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "95CUPsICvwVF",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "de1407ba-190c-4ec9-e68d-d4f13a51e5e5"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-95f0913a-ab50-45f4-9f39-da5520894022\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-95f0913a-ab50-45f4-9f39-da5520894022\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Tweets.csv to Tweets.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCM4qKF5RVvO"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQYO3L6ARVvW"
      },
      "source": [
        "df = pd.read_csv('Tweets.csv')\n",
        "labels = np.array(df['airline_sentiment'])\n",
        "reviews = np.array(df['text'])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efSB76FERVvn"
      },
      "source": [
        "## Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6r5c_IjRVvo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "282bb036-c48d-4e42-c704-153897a2e5e3"
      },
      "source": [
        "# Import Libraries\n",
        "\n",
        "import re\n",
        "import math \n",
        "import nltk\n",
        "import json\n",
        "import pandas as pd\n",
        "from progressbar import ProgressBar\n",
        "from nltk.tokenize.regexp import WordPunctTokenizer\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords \n",
        "from wordcloud import WordCloud\n",
        "from nltk.tokenize import word_tokenize \n",
        "\n",
        "pbar = ProgressBar()\n",
        "from nltk.stem import wordnet \n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "\n",
        "\n",
        "nltk.download('wordnet')\n",
        "\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "def filter(neutral):\n",
        "  neutral = ''.join(neutral)\n",
        "  neutral = re.sub(r'[\\'/0-9]', '', neutral)\n",
        "  neutral = re.sub(r'[?...#\"-&!---;:]', ' ', neutral)\n",
        "  neutral = neutral.lower()\n",
        "  neutral = re.sub(r'^@[/W].*', '', neutral)\n",
        "  #neutral = emoji.demojize(neutral, delimiters=(\" \", \" \")) \n",
        "  lemma = wordnet.WordNetLemmatizer()\n",
        "  stopwords_bag = set(stopwords.words(\"english\")) # Downloading all the dfault stop words in english language\n",
        "  tokens = word_tokenize(neutral) \n",
        "  final_text = [i for i in tokens if i not in stopwords_bag] # keep only those words which are not in stopword bag\n",
        "  final_text = [lemma.lemmatize(word) for word in final_text] \n",
        "  output = []\n",
        "  for i in final_text:\n",
        "    if(i[0] != '@'):\n",
        "      output.append(i)\n",
        "      \n",
        "  return output"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWVrAbkvzxvL",
        "outputId": "d70ef38e-6d38-4af3-ce7d-f66977abe151"
      },
      "source": [
        "words = filter(reviews)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:30: FutureWarning: Possible set difference at position 10\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8CUsAm4RVv0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c1be4b0-6349-45b7-93f2-1e7251d5a6d1"
      },
      "source": [
        "words[:100]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['virginamerica',\n",
              " 'dhepburn',\n",
              " 'said',\n",
              " 'virginamerica',\n",
              " 'plus',\n",
              " 'youve',\n",
              " 'added',\n",
              " 'commercial',\n",
              " 'experience',\n",
              " 'tacky',\n",
              " 'virginamerica',\n",
              " 'didnt',\n",
              " 'today',\n",
              " 'must',\n",
              " 'mean',\n",
              " 'need',\n",
              " 'take',\n",
              " 'another',\n",
              " 'trip',\n",
              " 'virginamerica',\n",
              " 'really',\n",
              " 'aggressive',\n",
              " 'blast',\n",
              " 'obnoxious',\n",
              " 'entertainment',\n",
              " 'guest',\n",
              " 'face',\n",
              " 'amp',\n",
              " 'little',\n",
              " 'recourse',\n",
              " 'virginamerica',\n",
              " 'really',\n",
              " 'big',\n",
              " 'bad',\n",
              " 'thing',\n",
              " 'virginamerica',\n",
              " 'seriously',\n",
              " 'would',\n",
              " 'pay',\n",
              " 'flight',\n",
              " 'seat',\n",
              " 'didnt',\n",
              " 'playing',\n",
              " 'really',\n",
              " 'bad',\n",
              " 'thing',\n",
              " 'flying',\n",
              " 'va',\n",
              " 'virginamerica',\n",
              " 'yes',\n",
              " 'nearly',\n",
              " 'every',\n",
              " 'time',\n",
              " 'fly',\n",
              " 'vx',\n",
              " '“',\n",
              " 'ear',\n",
              " 'worm',\n",
              " '”',\n",
              " '’',\n",
              " 'go',\n",
              " 'away',\n",
              " 'virginamerica',\n",
              " 'really',\n",
              " 'missed',\n",
              " 'prime',\n",
              " 'opportunity',\n",
              " 'men',\n",
              " 'without',\n",
              " 'hat',\n",
              " 'parody',\n",
              " 'http',\n",
              " 'comwpggrezp',\n",
              " 'virginamerica',\n",
              " 'well',\n",
              " 'didnt…but',\n",
              " 'virginamerica',\n",
              " 'amazing',\n",
              " 'arrived',\n",
              " 'hour',\n",
              " 'early',\n",
              " 'youre',\n",
              " 'good',\n",
              " 'virginamerica',\n",
              " 'know',\n",
              " 'suicide',\n",
              " 'second',\n",
              " 'leading',\n",
              " 'cause',\n",
              " 'death',\n",
              " 'among',\n",
              " 'teen',\n",
              " 'virginamerica',\n",
              " 'lt',\n",
              " 'pretty',\n",
              " 'graphic',\n",
              " 'much',\n",
              " 'better',\n",
              " 'minimal',\n",
              " 'iconography']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n_27QUtRVv6"
      },
      "source": [
        "### Encoding the words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uo2c7s8lRVv7"
      },
      "source": [
        "from collections import Counter\n",
        "counts = Counter(words)\n",
        "vocab = sorted(counts, key=counts.get, reverse=True)\n",
        "\n",
        "# Create your dictionary that maps vocab words to integers here\n",
        "vocab_to_int = {word: i for i, word in enumerate(vocab, 1)} # start from 1\n",
        "\n",
        "# Convert the reviews to integers, same shape as reviews list, but with integers\n",
        "review_ints = []\n",
        "for each in words:\n",
        "    review_ints.append([vocab_to_int[word] for word in each.split()])"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_jgY-5jzxiO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ae112f1-a754-4ed9-8ad8-3439a961f051"
      },
      "source": [
        "vocab_to_int"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'flight': 1,\n",
              " 'united': 2,\n",
              " 'usairways': 3,\n",
              " 'americanair': 4,\n",
              " 'southwestair': 5,\n",
              " 'jetblue': 6,\n",
              " 'get': 7,\n",
              " 'http': 8,\n",
              " 'hour': 9,\n",
              " 'thanks': 10,\n",
              " 'cancelled': 11,\n",
              " 'u': 12,\n",
              " 'service': 13,\n",
              " 'time': 14,\n",
              " 'customer': 15,\n",
              " 'help': 16,\n",
              " 'bag': 17,\n",
              " 'im': 18,\n",
              " 'plane': 19,\n",
              " 'amp': 20,\n",
              " 'hold': 21,\n",
              " 'need': 22,\n",
              " 'thank': 23,\n",
              " 'one': 24,\n",
              " 'still': 25,\n",
              " 'cant': 26,\n",
              " 'day': 27,\n",
              " 'please': 28,\n",
              " 'call': 29,\n",
              " 'airline': 30,\n",
              " 'would': 31,\n",
              " 'gate': 32,\n",
              " 'delayed': 33,\n",
              " 'back': 34,\n",
              " 'virginamerica': 35,\n",
              " 'flightled': 36,\n",
              " 'dont': 37,\n",
              " 'got': 38,\n",
              " 'seat': 39,\n",
              " 'phone': 40,\n",
              " 'delay': 41,\n",
              " 'like': 42,\n",
              " 'today': 43,\n",
              " 'hr': 44,\n",
              " 'late': 45,\n",
              " 'guy': 46,\n",
              " 'agent': 47,\n",
              " 'fly': 48,\n",
              " 'ticket': 49,\n",
              " 'know': 50,\n",
              " 'min': 51,\n",
              " 'make': 52,\n",
              " 'way': 53,\n",
              " 'airport': 54,\n",
              " 'waiting': 55,\n",
              " 'change': 56,\n",
              " 'minute': 57,\n",
              " 'trying': 58,\n",
              " 'go': 59,\n",
              " 'great': 60,\n",
              " 'ive': 61,\n",
              " 'going': 62,\n",
              " 'wait': 63,\n",
              " 'never': 64,\n",
              " 'flying': 65,\n",
              " 'problem': 66,\n",
              " 'weather': 67,\n",
              " 'tomorrow': 68,\n",
              " 'last': 69,\n",
              " 'check': 70,\n",
              " 'really': 71,\n",
              " 'good': 72,\n",
              " 'take': 73,\n",
              " 'even': 74,\n",
              " 'home': 75,\n",
              " 'people': 76,\n",
              " 'aa': 77,\n",
              " 'want': 78,\n",
              " 'issue': 79,\n",
              " 'another': 80,\n",
              " 'new': 81,\n",
              " 'told': 82,\n",
              " 'work': 83,\n",
              " 'first': 84,\n",
              " 'see': 85,\n",
              " 'luggage': 86,\n",
              " 'say': 87,\n",
              " 'number': 88,\n",
              " 'dm': 89,\n",
              " 'travel': 90,\n",
              " 'love': 91,\n",
              " 'email': 92,\n",
              " 'could': 93,\n",
              " 'ever': 94,\n",
              " 'let': 95,\n",
              " 'crew': 96,\n",
              " 'getting': 97,\n",
              " 'due': 98,\n",
              " 'someone': 99,\n",
              " 'lost': 100,\n",
              " 'worst': 101,\n",
              " 'yes': 102,\n",
              " 'thats': 103,\n",
              " 'next': 104,\n",
              " 'reservation': 105,\n",
              " 'passenger': 106,\n",
              " 'trip': 107,\n",
              " 'much': 108,\n",
              " 'baggage': 109,\n",
              " 'flighted': 110,\n",
              " 'ua': 111,\n",
              " 'two': 112,\n",
              " 'response': 113,\n",
              " 'right': 114,\n",
              " 'experience': 115,\n",
              " 'made': 116,\n",
              " 'line': 117,\n",
              " 'didnt': 118,\n",
              " 'well': 119,\n",
              " 'give': 120,\n",
              " '”': 121,\n",
              " 'jfk': 122,\n",
              " 'week': 123,\n",
              " 'online': 124,\n",
              " 'sitting': 125,\n",
              " '“': 126,\n",
              " 'best': 127,\n",
              " 'sent': 128,\n",
              " 'staff': 129,\n",
              " 'bad': 130,\n",
              " 'book': 131,\n",
              " 'connection': 132,\n",
              " 'boarding': 133,\n",
              " 'better': 134,\n",
              " 'already': 135,\n",
              " 'long': 136,\n",
              " 'said': 137,\n",
              " 'booked': 138,\n",
              " 'left': 139,\n",
              " 'sure': 140,\n",
              " 'wont': 141,\n",
              " 'since': 142,\n",
              " 'doesnt': 143,\n",
              " 'pm': 144,\n",
              " 'stuck': 145,\n",
              " 'youre': 146,\n",
              " 'ill': 147,\n",
              " 'mile': 148,\n",
              " 'keep': 149,\n",
              " 'morning': 150,\n",
              " 'look': 151,\n",
              " 'w': 152,\n",
              " 'tell': 153,\n",
              " 'system': 154,\n",
              " 'tonight': 155,\n",
              " 'dfw': 156,\n",
              " 'miss': 157,\n",
              " 'think': 158,\n",
              " 'flightr': 159,\n",
              " 'find': 160,\n",
              " 'care': 161,\n",
              " 'website': 162,\n",
              " 'whats': 163,\n",
              " 'night': 164,\n",
              " 'hotel': 165,\n",
              " 'nothing': 166,\n",
              " 'flt': 167,\n",
              " 'yet': 168,\n",
              " 'refund': 169,\n",
              " 'lax': 170,\n",
              " 'update': 171,\n",
              " 'fleet': 172,\n",
              " 'fleek': 173,\n",
              " 'use': 174,\n",
              " 'booking': 175,\n",
              " 'attendant': 176,\n",
              " 'put': 177,\n",
              " '’': 178,\n",
              " 'year': 179,\n",
              " 'info': 180,\n",
              " 'tried': 181,\n",
              " 'air': 182,\n",
              " 'pilot': 183,\n",
              " 'hope': 184,\n",
              " 'called': 185,\n",
              " 'pay': 186,\n",
              " 'rebooked': 187,\n",
              " 'anything': 188,\n",
              " 'answer': 189,\n",
              " 'rude': 190,\n",
              " 'missed': 191,\n",
              " 'ago': 192,\n",
              " 'also': 193,\n",
              " 'voucher': 194,\n",
              " 'thing': 195,\n",
              " 'free': 196,\n",
              " 'done': 197,\n",
              " 'follow': 198,\n",
              " 'nice': 199,\n",
              " 'credit': 200,\n",
              " 'point': 201,\n",
              " 'rep': 202,\n",
              " 'class': 203,\n",
              " 'sfo': 204,\n",
              " 'b': 205,\n",
              " 'come': 206,\n",
              " 'finally': 207,\n",
              " 'rebook': 208,\n",
              " 'option': 209,\n",
              " 'phl': 210,\n",
              " 'employee': 211,\n",
              " 'st': 212,\n",
              " 'awesome': 213,\n",
              " 'board': 214,\n",
              " 'able': 215,\n",
              " 'upgrade': 216,\n",
              " 'checked': 217,\n",
              " 'wifi': 218,\n",
              " 'ord': 219,\n",
              " 'working': 220,\n",
              " 'fee': 221,\n",
              " 'business': 222,\n",
              " 'every': 223,\n",
              " 'dca': 224,\n",
              " 'appreciate': 225,\n",
              " 'anyone': 226,\n",
              " 'missing': 227,\n",
              " 'team': 228,\n",
              " 'looking': 229,\n",
              " 'available': 230,\n",
              " 'show': 231,\n",
              " 'person': 232,\n",
              " 'delta': 233,\n",
              " 'status': 234,\n",
              " 'via': 235,\n",
              " 'id': 236,\n",
              " 'app': 237,\n",
              " 'yesterday': 238,\n",
              " 'always': 239,\n",
              " 'without': 240,\n",
              " 'name': 241,\n",
              " 'making': 242,\n",
              " 'leave': 243,\n",
              " 'many': 244,\n",
              " 'claim': 245,\n",
              " 'suck': 246,\n",
              " 'ok': 247,\n",
              " 'thx': 248,\n",
              " 'terrible': 249,\n",
              " 'couldnt': 250,\n",
              " 'helpful': 251,\n",
              " 'gt': 252,\n",
              " 'sorry': 253,\n",
              " 'understand': 254,\n",
              " 'disappointed': 255,\n",
              " 'open': 256,\n",
              " 'departure': 257,\n",
              " 'isnt': 258,\n",
              " 'clt': 259,\n",
              " 'bos': 260,\n",
              " 'fail': 261,\n",
              " 'extra': 262,\n",
              " 'instead': 263,\n",
              " 'early': 264,\n",
              " 'la': 265,\n",
              " 'stop': 266,\n",
              " 'amazing': 267,\n",
              " 'ewr': 268,\n",
              " 'speak': 269,\n",
              " 'bc': 270,\n",
              " 'fix': 271,\n",
              " 'friend': 272,\n",
              " 'hi': 273,\n",
              " 'southwest': 274,\n",
              " 'send': 275,\n",
              " 'paid': 276,\n",
              " 'money': 277,\n",
              " 'almost': 278,\n",
              " 'havent': 279,\n",
              " 'though': 280,\n",
              " 'lot': 281,\n",
              " 'site': 282,\n",
              " 'earlier': 283,\n",
              " 'contact': 284,\n",
              " 'wasnt': 285,\n",
              " 'family': 286,\n",
              " 'tweet': 287,\n",
              " 'pas': 288,\n",
              " 'talk': 289,\n",
              " 'try': 290,\n",
              " 'chance': 291,\n",
              " 'mean': 292,\n",
              " 'boston': 293,\n",
              " 'full': 294,\n",
              " 'took': 295,\n",
              " 'add': 296,\n",
              " 'different': 297,\n",
              " 'connecting': 298,\n",
              " 'policy': 299,\n",
              " 'happy': 300,\n",
              " 'job': 301,\n",
              " 'company': 302,\n",
              " 'rt': 303,\n",
              " 'dallas': 304,\n",
              " 'supposed': 305,\n",
              " 'card': 306,\n",
              " 'vega': 307,\n",
              " 'hung': 308,\n",
              " 'unacceptable': 309,\n",
              " 'something': 310,\n",
              " 'ridiculous': 311,\n",
              " 'airway': 312,\n",
              " 'member': 313,\n",
              " 'month': 314,\n",
              " 'received': 315,\n",
              " 'least': 316,\n",
              " 'wife': 317,\n",
              " 'direct': 318,\n",
              " 'question': 319,\n",
              " 'ground': 320,\n",
              " 'start': 321,\n",
              " 'th': 322,\n",
              " 'horrible': 323,\n",
              " 'poor': 324,\n",
              " 'actually': 325,\n",
              " 'oh': 326,\n",
              " 'chicago': 327,\n",
              " 'stranded': 328,\n",
              " 'old': 329,\n",
              " 'reason': 330,\n",
              " 'tarmac': 331,\n",
              " 'message': 332,\n",
              " 'denver': 333,\n",
              " 'destinationdragons': 334,\n",
              " 'everyone': 335,\n",
              " 'yall': 336,\n",
              " 'landed': 337,\n",
              " 'san': 338,\n",
              " 'calling': 339,\n",
              " 'snow': 340,\n",
              " 'twitter': 341,\n",
              " 'c': 342,\n",
              " 'charge': 343,\n",
              " 'found': 344,\n",
              " 'seriously': 345,\n",
              " 'taking': 346,\n",
              " 'american': 347,\n",
              " 'ur': 348,\n",
              " 'account': 349,\n",
              " 'leaving': 350,\n",
              " 'offer': 351,\n",
              " 'maybe': 352,\n",
              " 'vacation': 353,\n",
              " 'reply': 354,\n",
              " 'far': 355,\n",
              " 'away': 356,\n",
              " 'nyc': 357,\n",
              " 'food': 358,\n",
              " 'desk': 359,\n",
              " 'wrong': 360,\n",
              " 'might': 361,\n",
              " 'gave': 362,\n",
              " 'kid': 363,\n",
              " 'cost': 364,\n",
              " 'half': 365,\n",
              " 'big': 366,\n",
              " 'return': 367,\n",
              " 'enough': 368,\n",
              " 'sit': 369,\n",
              " 'went': 370,\n",
              " 'frustrated': 371,\n",
              " 'coming': 372,\n",
              " 'destination': 373,\n",
              " 'complaint': 374,\n",
              " 'may': 375,\n",
              " 'three': 376,\n",
              " 'confirmation': 377,\n",
              " 'past': 378,\n",
              " 'row': 379,\n",
              " 'mechanical': 380,\n",
              " 'car': 381,\n",
              " 'there': 382,\n",
              " 'twice': 383,\n",
              " 'little': 384,\n",
              " 'feel': 385,\n",
              " 'together': 386,\n",
              " 'using': 387,\n",
              " 'plan': 388,\n",
              " 'hey': 389,\n",
              " 'changed': 390,\n",
              " 'link': 391,\n",
              " 'broken': 392,\n",
              " 'stay': 393,\n",
              " 'asked': 394,\n",
              " 'soon': 395,\n",
              " 'le': 396,\n",
              " 'deal': 397,\n",
              " 'iad': 398,\n",
              " 'around': 399,\n",
              " 'pls': 400,\n",
              " 'possible': 401,\n",
              " 'newark': 402,\n",
              " 'charlotte': 403,\n",
              " 'runway': 404,\n",
              " 'error': 405,\n",
              " 'apology': 406,\n",
              " 'saying': 407,\n",
              " 'idea': 408,\n",
              " 'phx': 409,\n",
              " 'life': 410,\n",
              " 'worse': 411,\n",
              " 'houston': 412,\n",
              " 'terminal': 413,\n",
              " 'used': 414,\n",
              " 'fll': 415,\n",
              " 'cool': 416,\n",
              " 'longer': 417,\n",
              " 'guess': 418,\n",
              " 'weve': 419,\n",
              " 'city': 420,\n",
              " 'lga': 421,\n",
              " 'landing': 422,\n",
              " 'traveling': 423,\n",
              " 'real': 424,\n",
              " 'second': 425,\n",
              " 'given': 426,\n",
              " 'awful': 427,\n",
              " 'plus': 428,\n",
              " 'scheduled': 429,\n",
              " 'price': 430,\n",
              " 'computer': 431,\n",
              " 'room': 432,\n",
              " 'hard': 433,\n",
              " 'waited': 434,\n",
              " 'seems': 435,\n",
              " 'thought': 436,\n",
              " 'k': 437,\n",
              " 'lack': 438,\n",
              " 'telling': 439,\n",
              " 'youve': 440,\n",
              " 'end': 441,\n",
              " 'sat': 442,\n",
              " 'iah': 443,\n",
              " 'thru': 444,\n",
              " 'hear': 445,\n",
              " 'frustrating': 446,\n",
              " 'arrived': 447,\n",
              " 'heard': 448,\n",
              " 'fare': 449,\n",
              " 'philly': 450,\n",
              " 'else': 451,\n",
              " 'believe': 452,\n",
              " 'den': 453,\n",
              " 'pick': 454,\n",
              " 'happened': 455,\n",
              " 'na': 456,\n",
              " 'request': 457,\n",
              " 'international': 458,\n",
              " 'hang': 459,\n",
              " 'nd': 460,\n",
              " 'assistance': 461,\n",
              " 'dc': 462,\n",
              " 'route': 463,\n",
              " 'cust': 464,\n",
              " 'jet': 465,\n",
              " 'information': 466,\n",
              " 'arrive': 467,\n",
              " 'human': 468,\n",
              " 'monday': 469,\n",
              " 'standby': 470,\n",
              " 'hoping': 471,\n",
              " 'miami': 472,\n",
              " 'leg': 473,\n",
              " 'wouldnt': 474,\n",
              " 'bwi': 475,\n",
              " 'reflight': 476,\n",
              " 'maintenance': 477,\n",
              " 'award': 478,\n",
              " 'everything': 479,\n",
              " 'process': 480,\n",
              " 'quick': 481,\n",
              " 'place': 482,\n",
              " 'carry': 483,\n",
              " 'loyal': 484,\n",
              " 'swa': 485,\n",
              " 'world': 486,\n",
              " 'glad': 487,\n",
              " 'joke': 488,\n",
              " 'lol': 489,\n",
              " 'forward': 490,\n",
              " 'expect': 491,\n",
              " 'group': 492,\n",
              " 'counting': 493,\n",
              " 'usair': 494,\n",
              " 'mco': 495,\n",
              " 'club': 496,\n",
              " 'wanted': 497,\n",
              " 'yr': 498,\n",
              " 'ceo': 499,\n",
              " 'ask': 500,\n",
              " 'word': 501,\n",
              " 'reach': 502,\n",
              " 'date': 503,\n",
              " 'communication': 504,\n",
              " 'needed': 505,\n",
              " 'arent': 506,\n",
              " 'busy': 507,\n",
              " 'tv': 508,\n",
              " 'checking': 509,\n",
              " 'child': 510,\n",
              " 'case': 511,\n",
              " 'form': 512,\n",
              " 'spent': 513,\n",
              " 'non': 514,\n",
              " 'flyer': 515,\n",
              " 'wish': 516,\n",
              " 'boarded': 517,\n",
              " 'run': 518,\n",
              " 'flew': 519,\n",
              " 'bring': 520,\n",
              " 'paying': 521,\n",
              " 'empty': 522,\n",
              " 'address': 523,\n",
              " 'unitedairlines': 524,\n",
              " 'theyre': 525,\n",
              " 'hate': 526,\n",
              " 'sunday': 527,\n",
              " 'sw': 528,\n",
              " 'imaginedragons': 529,\n",
              " 'blue': 530,\n",
              " 'wow': 531,\n",
              " 'traveler': 532,\n",
              " 'yeah': 533,\n",
              " 'provide': 534,\n",
              " 'tsa': 535,\n",
              " 'buy': 536,\n",
              " 'entire': 537,\n",
              " 'asking': 538,\n",
              " 'counter': 539,\n",
              " 'list': 540,\n",
              " 'cause': 541,\n",
              " 'bought': 542,\n",
              " 'lose': 543,\n",
              " 'drive': 544,\n",
              " 'taken': 545,\n",
              " 'pretty': 546,\n",
              " 'worry': 547,\n",
              " 'happens': 548,\n",
              " 'respond': 549,\n",
              " 'helping': 550,\n",
              " 'currently': 551,\n",
              " 'whole': 552,\n",
              " 'flighting': 553,\n",
              " 'supervisor': 554,\n",
              " 'rather': 555,\n",
              " 'hopefully': 556,\n",
              " 'either': 557,\n",
              " 'rock': 558,\n",
              " 'asap': 559,\n",
              " 'detail': 560,\n",
              " 'seem': 561,\n",
              " 'sleep': 562,\n",
              " 'happen': 563,\n",
              " 'situation': 564,\n",
              " 'fault': 565,\n",
              " 'nashville': 566,\n",
              " 'live': 567,\n",
              " 'companion': 568,\n",
              " 'beyond': 569,\n",
              " 'moved': 570,\n",
              " 'super': 571,\n",
              " 'confirmed': 572,\n",
              " 'treat': 573,\n",
              " 'x': 574,\n",
              " 'future': 575,\n",
              " 'atl': 576,\n",
              " 'flightlations': 577,\n",
              " 'appreciated': 578,\n",
              " 'holding': 579,\n",
              " 'support': 580,\n",
              " 'fine': 581,\n",
              " 'correct': 582,\n",
              " 'austin': 583,\n",
              " 'wtf': 584,\n",
              " 'ready': 585,\n",
              " 'storm': 586,\n",
              " 'figure': 587,\n",
              " 'automated': 588,\n",
              " 'lt': 589,\n",
              " 'easy': 590,\n",
              " 'high': 591,\n",
              " 'land': 592,\n",
              " 'shouldnt': 593,\n",
              " 'cabin': 594,\n",
              " 'safety': 595,\n",
              " 'purchase': 596,\n",
              " 'upset': 597,\n",
              " 'record': 598,\n",
              " 'top': 599,\n",
              " 'okay': 600,\n",
              " 'door': 601,\n",
              " 'feb': 602,\n",
              " 'medium': 603,\n",
              " 'e': 604,\n",
              " 'sad': 605,\n",
              " 'offered': 606,\n",
              " 'luv': 607,\n",
              " 'apparently': 608,\n",
              " 'handle': 609,\n",
              " 'drink': 610,\n",
              " 'access': 611,\n",
              " 'lie': 612,\n",
              " 'set': 613,\n",
              " 'part': 614,\n",
              " 'orlando': 615,\n",
              " 'read': 616,\n",
              " 'tuesday': 617,\n",
              " 'mia': 618,\n",
              " 'atlanta': 619,\n",
              " 'share': 620,\n",
              " 'layover': 621,\n",
              " 'customerservice': 622,\n",
              " 'flown': 623,\n",
              " 'completely': 624,\n",
              " 'probably': 625,\n",
              " 'switch': 626,\n",
              " 'following': 627,\n",
              " 'disconnected': 628,\n",
              " 'running': 629,\n",
              " 'priority': 630,\n",
              " 'reschedule': 631,\n",
              " 'checkin': 632,\n",
              " 'r': 633,\n",
              " 'charged': 634,\n",
              " 'helped': 635,\n",
              " 'luck': 636,\n",
              " 'platinum': 637,\n",
              " 'zero': 638,\n",
              " 'weekend': 639,\n",
              " 'compensation': 640,\n",
              " 'original': 641,\n",
              " 'fact': 642,\n",
              " 'huge': 643,\n",
              " 'kind': 644,\n",
              " 'must': 645,\n",
              " 'schedule': 646,\n",
              " 'cold': 647,\n",
              " 'middle': 648,\n",
              " 'shes': 649,\n",
              " 'giving': 650,\n",
              " 'gon': 651,\n",
              " 'husband': 652,\n",
              " 'shit': 653,\n",
              " 'matter': 654,\n",
              " 'clothes': 655,\n",
              " 'lounge': 656,\n",
              " 'delivered': 657,\n",
              " 'seen': 658,\n",
              " 'allowed': 659,\n",
              " 'sending': 660,\n",
              " 'losing': 661,\n",
              " 'wall': 662,\n",
              " 'allow': 663,\n",
              " 'f': 664,\n",
              " 'load': 665,\n",
              " 'front': 666,\n",
              " 'flightlation': 667,\n",
              " 'report': 668,\n",
              " 'fun': 669,\n",
              " 'several': 670,\n",
              " 'space': 671,\n",
              " '=': 672,\n",
              " 'explain': 673,\n",
              " 'daughter': 674,\n",
              " 'mom': 675,\n",
              " 'winter': 676,\n",
              " 'arrival': 677,\n",
              " 'ice': 678,\n",
              " 'rdu': 679,\n",
              " 'changing': 680,\n",
              " 'country': 681,\n",
              " 'answering': 682,\n",
              " 'oscar': 683,\n",
              " 'four': 684,\n",
              " 'trouble': 685,\n",
              " 'pre': 686,\n",
              " 'gold': 687,\n",
              " 'came': 688,\n",
              " 'despite': 689,\n",
              " 'round': 690,\n",
              " 'aircraft': 691,\n",
              " 'extremely': 692,\n",
              " 'multiple': 693,\n",
              " 'meal': 694,\n",
              " 'crazy': 695,\n",
              " 'hello': 696,\n",
              " 'relation': 697,\n",
              " 'water': 698,\n",
              " 'letter': 699,\n",
              " 'dividend': 700,\n",
              " 'birthday': 701,\n",
              " 'friendly': 702,\n",
              " 'notification': 703,\n",
              " 'inconvenience': 704,\n",
              " 'spoke': 705,\n",
              " 'rd': 706,\n",
              " 'tix': 707,\n",
              " 'ppl': 708,\n",
              " 'baby': 709,\n",
              " 'held': 710,\n",
              " 'drop': 711,\n",
              " 'note': 712,\n",
              " 'unfortunately': 713,\n",
              " 'fixed': 714,\n",
              " 'unable': 715,\n",
              " 'sense': 716,\n",
              " 'attitude': 717,\n",
              " 'bna': 718,\n",
              " 'news': 719,\n",
              " 'sign': 720,\n",
              " 'mobile': 721,\n",
              " 'folk': 722,\n",
              " 'friday': 723,\n",
              " 'choice': 724,\n",
              " 'item': 725,\n",
              " 'area': 726,\n",
              " 'complete': 727,\n",
              " 'knew': 728,\n",
              " 'mine': 729,\n",
              " 'excuse': 730,\n",
              " 'true': 731,\n",
              " 'program': 732,\n",
              " 'page': 733,\n",
              " 'lady': 734,\n",
              " 'code': 735,\n",
              " 'totally': 736,\n",
              " 'fl': 737,\n",
              " 'afternoon': 738,\n",
              " 'rescheduled': 739,\n",
              " 'absolutely': 740,\n",
              " 'mileage': 741,\n",
              " 'turn': 742,\n",
              " 'meeting': 743,\n",
              " 'short': 744,\n",
              " 'overnight': 745,\n",
              " 'concern': 746,\n",
              " 'confirm': 747,\n",
              " 'nope': 748,\n",
              " 'responding': 749,\n",
              " 'dealing': 750,\n",
              " 'control': 751,\n",
              " 'treated': 752,\n",
              " 'hasnt': 753,\n",
              " 'haha': 754,\n",
              " 'jetblues': 755,\n",
              " 'virgin': 756,\n",
              " 'spend': 757,\n",
              " 'americanairlines': 758,\n",
              " 'itinerary': 759,\n",
              " 'small': 760,\n",
              " 'course': 761,\n",
              " 'learn': 762,\n",
              " 'man': 763,\n",
              " 'overhead': 764,\n",
              " 'wonderful': 765,\n",
              " 'son': 766,\n",
              " 'worth': 767,\n",
              " 'kudos': 768,\n",
              " 'n': 769,\n",
              " 'literally': 770,\n",
              " 'showing': 771,\n",
              " 'social': 772,\n",
              " 'p': 773,\n",
              " 'hand': 774,\n",
              " 'plz': 775,\n",
              " 'ride': 776,\n",
              " 'anyway': 777,\n",
              " 'closed': 778,\n",
              " 'ny': 779,\n",
              " 'bit': 780,\n",
              " 'march': 781,\n",
              " 'window': 782,\n",
              " 'evening': 783,\n",
              " 'excellent': 784,\n",
              " 'saw': 785,\n",
              " 'connect': 786,\n",
              " 'offering': 787,\n",
              " 'tag': 788,\n",
              " 'office': 789,\n",
              " 'explanation': 790,\n",
              " 'mess': 791,\n",
              " 'reward': 792,\n",
              " 'gone': 793,\n",
              " 'excited': 794,\n",
              " 'watch': 795,\n",
              " 'saturday': 796,\n",
              " 'depart': 797,\n",
              " 'passbook': 798,\n",
              " 'center': 799,\n",
              " 'story': 800,\n",
              " 'submitted': 801,\n",
              " 'wo': 802,\n",
              " 'mail': 803,\n",
              " 'anymore': 804,\n",
              " 'mistake': 805,\n",
              " 'arriving': 806,\n",
              " 'conf': 807,\n",
              " 'advisory': 808,\n",
              " 'feedback': 809,\n",
              " 'move': 810,\n",
              " 'neveragain': 811,\n",
              " 'letting': 812,\n",
              " 'failure': 813,\n",
              " 'airplane': 814,\n",
              " 'however': 815,\n",
              " 'volume': 816,\n",
              " 'seating': 817,\n",
              " 'win': 818,\n",
              " 'mind': 819,\n",
              " 'step': 820,\n",
              " 'kept': 821,\n",
              " 'web': 822,\n",
              " 'he': 823,\n",
              " 'behind': 824,\n",
              " 'post': 825,\n",
              " 'forced': 826,\n",
              " 'rate': 827,\n",
              " 'receipt': 828,\n",
              " 'worked': 829,\n",
              " 'anywhere': 830,\n",
              " 'followed': 831,\n",
              " 'phoenix': 832,\n",
              " 'catch': 833,\n",
              " 'usairwaysfail': 834,\n",
              " 'failed': 835,\n",
              " 'close': 836,\n",
              " 'entertainment': 837,\n",
              " 'select': 838,\n",
              " 'view': 839,\n",
              " 'video': 840,\n",
              " 'btw': 841,\n",
              " 'sound': 842,\n",
              " 'dollar': 843,\n",
              " 'started': 844,\n",
              " 'others': 845,\n",
              " 'domestic': 846,\n",
              " 'resolved': 847,\n",
              " 'ruined': 848,\n",
              " 'merger': 849,\n",
              " 'state': 850,\n",
              " 'fan': 851,\n",
              " 'cover': 852,\n",
              " 'none': 853,\n",
              " 'bumped': 854,\n",
              " 'funeral': 855,\n",
              " 'dragon': 856,\n",
              " 'warm': 857,\n",
              " 'takeoff': 858,\n",
              " 'dropped': 859,\n",
              " 'receive': 860,\n",
              " 'stuff': 861,\n",
              " 'frequent': 862,\n",
              " 'happening': 863,\n",
              " 'bank': 864,\n",
              " 'svc': 865,\n",
              " 'transfer': 866,\n",
              " 'refuse': 867,\n",
              " 'finger': 868,\n",
              " 'flightd': 869,\n",
              " 'caused': 870,\n",
              " 'captain': 871,\n",
              " 'updated': 872,\n",
              " 'keeping': 873,\n",
              " 'de': 874,\n",
              " 'safe': 875,\n",
              " 'sky': 876,\n",
              " 'useless': 877,\n",
              " 'special': 878,\n",
              " 'assist': 879,\n",
              " 'notice': 880,\n",
              " 'expected': 881,\n",
              " 'filed': 882,\n",
              " 'order': 883,\n",
              " 'au': 884,\n",
              " 'h': 885,\n",
              " 'moving': 886,\n",
              " 'intl': 887,\n",
              " 'unhelpful': 888,\n",
              " 'youll': 889,\n",
              " 'unhappy': 890,\n",
              " 'train': 891,\n",
              " 'tired': 892,\n",
              " 'promise': 893,\n",
              " 'single': 894,\n",
              " 'power': 895,\n",
              " 'hell': 896,\n",
              " 'acceptable': 897,\n",
              " 'party': 898,\n",
              " 'match': 899,\n",
              " 'current': 900,\n",
              " 'dal': 901,\n",
              " 'text': 902,\n",
              " 'representative': 903,\n",
              " 'absolute': 904,\n",
              " 'definitely': 905,\n",
              " 'count': 906,\n",
              " 'charging': 907,\n",
              " 'mexico': 908,\n",
              " 'philadelphia': 909,\n",
              " 'avgeek': 910,\n",
              " 'werent': 911,\n",
              " 'cut': 912,\n",
              " 'regarding': 913,\n",
              " 'resolve': 914,\n",
              " 'total': 915,\n",
              " 'announcement': 916,\n",
              " 'bird': 917,\n",
              " 'file': 918,\n",
              " 'onto': 919,\n",
              " 'forgot': 920,\n",
              " 'major': 921,\n",
              " 'final': 922,\n",
              " 'fair': 923,\n",
              " 'head': 924,\n",
              " 'woman': 925,\n",
              " 'cc': 926,\n",
              " 'impressed': 927,\n",
              " 'screwed': 928,\n",
              " 'suggestion': 929,\n",
              " 'kidding': 930,\n",
              " 'fucking': 931,\n",
              " 'except': 932,\n",
              " 'sister': 933,\n",
              " 'especially': 934,\n",
              " 'tmrw': 935,\n",
              " 'snack': 936,\n",
              " 'street': 937,\n",
              " 'carrier': 938,\n",
              " 'inflight': 939,\n",
              " 'planned': 940,\n",
              " 'nonstop': 941,\n",
              " 'headed': 942,\n",
              " 'mention': 943,\n",
              " 'suitcase': 944,\n",
              " 'funny': 945,\n",
              " 'nightmare': 946,\n",
              " 'actual': 947,\n",
              " 'auto': 948,\n",
              " 'security': 949,\n",
              " 'rule': 950,\n",
              " 'willing': 951,\n",
              " 'equipment': 952,\n",
              " 'pathetic': 953,\n",
              " 'talking': 954,\n",
              " 'screw': 955,\n",
              " 'premier': 956,\n",
              " 'clear': 957,\n",
              " 'damn': 958,\n",
              " 'fit': 959,\n",
              " 'difference': 960,\n",
              " 'badservice': 961,\n",
              " 'onboard': 962,\n",
              " 'answered': 963,\n",
              " 'compensate': 964,\n",
              " 'talked': 965,\n",
              " 'hanging': 966,\n",
              " 'per': 967,\n",
              " 'enjoy': 968,\n",
              " 'south': 969,\n",
              " 'added': 970,\n",
              " 'america': 971,\n",
              " 'emailed': 972,\n",
              " 'seattle': 973,\n",
              " 'purchased': 974,\n",
              " 'requested': 975,\n",
              " 'wondering': 976,\n",
              " 'sort': 977,\n",
              " 'resolution': 978,\n",
              " 'provided': 979,\n",
              " 'slow': 980,\n",
              " 'solution': 981,\n",
              " 'picked': 982,\n",
              " 'fyi': 983,\n",
              " 'favorite': 984,\n",
              " 'uk': 985,\n",
              " 'break': 986,\n",
              " 'crossed': 987,\n",
              " 'usually': 988,\n",
              " 'wed': 989,\n",
              " 'tweeting': 990,\n",
              " 'wasted': 991,\n",
              " 'photo': 992,\n",
              " 'tho': 993,\n",
              " 'denied': 994,\n",
              " 'angry': 995,\n",
              " 'departing': 996,\n",
              " 'sick': 997,\n",
              " 'listening': 998,\n",
              " 'bother': 999,\n",
              " 'broke': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4tKV6zcRVwB"
      },
      "source": [
        "### Encoding the labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x672-o_TRVwC"
      },
      "source": [
        "# Convert labels to 1s and 0s for 'positive' and 'negative'\n",
        "labels = np.array([1 if label == 'positive' else 0 for label in labels])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFxk4Ib2RVwH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e12b17f1-b2c1-4bc7-9462-c1a383a008f8"
      },
      "source": [
        "review_lens = Counter([len(x) for x in review_ints])\n",
        "print(\"Zero-length reviews: {}\".format(review_lens[0]))\n",
        "print(\"Maximum review length: {}\".format(max(review_lens)))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Zero-length reviews: 0\n",
            "Maximum review length: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EEulHd_RVwR"
      },
      "source": [
        "# Filter out that review with 0 length\n",
        "review_ints = [review for review in review_ints if (len(review) > 0)]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXbofAT2RVwa"
      },
      "source": [
        "seq_len = 200\n",
        "features = []\n",
        "for review in review_ints:\n",
        "    review_len = len(review)\n",
        "    len_diff = seq_len - review_len\n",
        "    if len_diff <= 0:\n",
        "        features.append(review[:seq_len])\n",
        "    else:\n",
        "        padding = [0] * len_diff\n",
        "        padded_feature = padding + review\n",
        "        features.append(padded_feature)\n",
        "\n",
        "features = np.asarray(features)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnq_42vyRVwf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "36658be9-2f0b-4c1c-9a4c-35644a21332f"
      },
      "source": [
        "features[:10,:100]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0, 21025,   308,     6,\n",
              "            3,  1050,   207,     8,  2138,    32,     1,   171,    57,\n",
              "           15,    49,    81,  5785,    44,   382,   110,   140,    15,\n",
              "         5194,    60,   154,     9,     1,  4975,  5852,   475,    71,\n",
              "            5,   260,    12, 21025,   308,    13,  1978,     6,    74,\n",
              "         2395],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,    63,     4,     3,   125,\n",
              "           36,    47,  7472,  1395,    16,     3,  4181,   505,    45,\n",
              "           17],\n",
              "       [22382,    42, 46418,    15,   706, 17139,  3389,    47,    77,\n",
              "           35,  1819,    16,   154,    19,   114,     3,  1305,     5,\n",
              "          336,   147,    22,     1,   857,    12,    70,   281,  1168,\n",
              "          399,    36,   120,   283,    38,   169,     5,   382,   158,\n",
              "           42,  2269,    16,     1,   541,    90,    78,   102,     4,\n",
              "            1,  3244,    15,    43,     3,   407,  1068,   136,  8055,\n",
              "           44,   182,   140,    15,  3043,     1,   320,    22,  4818,\n",
              "        26224,   346,     5,  3090,  2092,     1, 18839, 17939,    42,\n",
              "         8055,    46,    33,   236,    29,   370,     5,   130,    56,\n",
              "           22,     1,  1928,     7,     7,    19,    48,    46,    21,\n",
              "           70,   344,     3,  2099,     5,   408,    22,     1,  1928,\n",
              "           16],\n",
              "       [ 4505,   505,    15,     3,  3342,   162,  8312,  1652,     6,\n",
              "         4819,    56,    17,  4504,  5616,   140, 11725,     5,   996,\n",
              "         4919,  2933,  4462,   566,  1201,    36,     6,  1518,    96,\n",
              "            3,   744,     4, 26225,    13,     5,    27,  3461,     9,\n",
              "        10625,     4,     8,   111,  3013,     5,     1,  1027,    15,\n",
              "            3,  4390,    82,    22,  2049,     6,  4462,   538,  2764,\n",
              "         7073, 37443,    41,   463,     1,  8312, 46419,   302,   123,\n",
              "           15,  4221,    19,  1667,   922,     1,  1652,     6,  6129,\n",
              "        19871,    34,     1,   980,  1751, 22383,   646, 24104,    27,\n",
              "          106, 11726,    13, 14045, 15097, 17940,  2457,   466, 21027,\n",
              "           36,  3266,     1,  6365,  1020,    45,    17,  2695,  2499,\n",
              "           33],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,   520,   119,   113,    34,\n",
              "        16372,  1816,  3737,   117,   885, 21030,   721,    10,    28,\n",
              "          124,   108,     2,   115,   137,     9,  1623,  7691,    26,\n",
              "          330,     5,   589,     1,  6130,    22,   386,     6,     3,\n",
              "          349,    15,    50,    15,   231,     9,  7473, 11399,     1,\n",
              "          191,    22,  8966,     6,    82,   880,   101,   111,  3584,\n",
              "            4],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           11,    20,  3637,   141,    10,   422,    23,   272,    60,\n",
              "         4355,    22,    32,    84,  3286,    22,     1,   172,     4,\n",
              "            1,   952,   507,    11,  4977,  5361,     5,   574,     4,\n",
              "         1155,    54,    53,  5304,     1,   261,    17,    41,   952,\n",
              "          125,    59,     1,   711,   137,   379,   626,    15,   111,\n",
              "         1509],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,    11,     6,   692,     1,    90,\n",
              "         2156,    20, 11728,     1,  2818,  5195,   249,    92,  3006,\n",
              "            8,   126,    24,   200,     3,   802,   634,     4, 22382,\n",
              "         1001],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,   786,   295,    10,   122,    11,     6,   419,\n",
              "            5,    29,    35,   482,    20,    19,  1281,    33,   142,\n",
              "           28,  2657,    45,  1840,    32,     1,  2778,    37,    78,\n",
              "           97,  2436,    67,  3950,    45,     2,    24,   105,   256,\n",
              "            1,   134,  1571,     2, 12399,   451,    14,   319,    11,\n",
              "           63,     6,    98,  1321,     5,   105,     1,  3767,     4,\n",
              "            3],\n",
              "       [    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,    11,     6,\n",
              "           24,     1,   779,  3687,  2818,    20,     8,    14,    74,\n",
              "          325,  2730,    73,    90,     4,    27,    99,     2,   165,\n",
              "           68],\n",
              "       [   54,    10,    14,   116,    60,   798,   552,    71,   364,\n",
              "            5,     1,   730,     5,    66,  8057,     8,    14,    30,\n",
              "            4,   109,    99,    10,   293,    17,    60,   798,    19,\n",
              "           11,    14,     1,    64,    30,    69,  2500,    45,     4,\n",
              "          234,    93,    10,    68,   114,   108,  8057,   363,    43,\n",
              "         1009,     2,    10,    97,    28,  1431,    45,     1,   357,\n",
              "            4,    60,   110,   205,     8,    48,     3,  1929, 10880,\n",
              "            2,  2124,   354,   412,     4,    13,  6609,     2,  2974,\n",
              "         5148,  2125,  1366,     6,    30,     4,    60,   502,   876,\n",
              "           19,  8057,     6,    34,   227,     1,   247,   412,     4,\n",
              "          582,     4,    27,   599,     9,     1, 13586,   396,     4,\n",
              "        14047]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inlsPUdsRVwh"
      },
      "source": [
        "## Training, Validation, Test\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8TJf7t4RVwj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f256e827-26b6-4adb-e2c3-e63897a550e7"
      },
      "source": [
        "split_frac = 0.8\n",
        "split_idx = int(len(features) * split_frac)\n",
        "\n",
        "train_x, val_x = features[:split_idx], features[split_idx:]\n",
        "train_y, val_y = labels[:split_idx], labels[:split_idx]\n",
        "\n",
        "test_idx = int(len(val_x) * 0.5)\n",
        "val_x, test_x = val_x[:test_idx], val_x[test_idx:]\n",
        "val_y, test_y = val_y[:test_idx], val_y[test_idx:]\n",
        "\n",
        "print(\"\\t\\t\\tFeature Shapes:\")\n",
        "print(\"Train set: \\t\\t{}\".format(train_x.shape), \n",
        "      \"\\nValidation set: \\t{}\".format(val_x.shape),\n",
        "      \"\\nTest set: \\t\\t{}\".format(test_x.shape))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\t\t\tFeature Shapes:\n",
            "Train set: \t\t(120692, 200) \n",
            "Validation set: \t(15086, 200) \n",
            "Test set: \t\t(15087, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7yM6Nd_RVwn"
      },
      "source": [
        "## Build the graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ozi2pqYRVwn"
      },
      "source": [
        "lstm_size = 256\n",
        "lstm_layers = 1\n",
        "batch_size = 500\n",
        "learning_rate = 0.001"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTs9BsYFRVw2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3900d25-05ef-47b8-89fc-561097512e62"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior() \n",
        "n_words = len(vocab)\n",
        "\n",
        "# Create the graph object\n",
        "graph = tf.Graph()\n",
        "# Add nodes to the graph\n",
        "with graph.as_default():\n",
        "    inputs_ = tf.placeholder(tf.int32, shape=(None, None), name=\"inputs\")\n",
        "    labels_ = tf.placeholder(tf.int32, shape=(None, None), name=\"labels\")\n",
        "    keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky_XPayKRVw6"
      },
      "source": [
        "### Embedding\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWtoqAbhRVw8"
      },
      "source": [
        "# Size of the embedding vectors (number of units in the embedding layer)\n",
        "embed_size = 300 \n",
        "\n",
        "with graph.as_default():\n",
        "    embedding = tf.Variable(tf.random_uniform([n_words, embed_size], -1.0, 1.0))\n",
        "    embed = tf.nn.embedding_lookup(embedding, inputs_)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpzCpW-wRVxA"
      },
      "source": [
        "### LSTM cell\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v87US0NzRVxB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8c61c13-a4bd-45d6-e5b1-1efe6c86bd7d"
      },
      "source": [
        "import tensorflow as tf\n",
        "with graph.as_default():\n",
        "    # Your basic LSTM cell\n",
        "    lstm =  tf.compat.v1.nn.rnn_cell.BasicLSTMCell(lstm_size)\n",
        "    \n",
        "    # Add dropout to the cell\n",
        "    drop =  tf.compat.v1.nn.rnn_cell.DropoutWrapper(lstm, output_keep_prob=keep_prob)\n",
        "    \n",
        "    # Stack up multiple LSTM layers, for deep learning\n",
        "    cell =  tf.compat.v1.nn.rnn_cell.MultiRNNCell([drop] * lstm_layers)\n",
        "    \n",
        "    # Getting an initial state of all zeros\n",
        "    initial_state = cell.zero_state(batch_size, tf.float32)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:708: UserWarning: `tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  warnings.warn(\"`tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PF1smALJRVxF"
      },
      "source": [
        "### RNN forward pass\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBqzmOvERVxG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1286c160-83d9-42a5-9f8f-fe8e4466c853"
      },
      "source": [
        "with graph.as_default():\n",
        "    outputs, final_state = tf.compat.v1.nn.dynamic_rnn(cell, embed, initial_state=initial_state)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-51-8295fd0ac1ec>:2: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:759: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1700: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
            "  warnings.warn('`layer.add_variable` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR9CMCk_RVxL"
      },
      "source": [
        "### Output\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ze4fyMDnRVxN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a220db13-50f1-4db8-c79e-61b72bbfe337"
      },
      "source": [
        "with graph.as_default():\n",
        "    predictions = tf.compat.v1.layers.dense(outputs[:, -1], 1, activation=tf.sigmoid)\n",
        "    cost = tf.losses.mean_squared_error(labels_, predictions)\n",
        "    \n",
        "    optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate).minimize(cost)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/legacy_tf_layers/core.py:171: UserWarning: `tf.layers.dense` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dense` instead.\n",
            "  warnings.warn('`tf.layers.dense` is deprecated and '\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_v1.py:1692: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  warnings.warn('`layer.apply` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUJSacClRVxR"
      },
      "source": [
        "### Validation accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHL7ojAqRVxR"
      },
      "source": [
        "with graph.as_default():\n",
        "    correct_pred = tf.equal(tf.cast(tf.round(predictions), tf.int32), labels_)\n",
        "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ujOIadrRVxa"
      },
      "source": [
        "### Batching\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFJuy298RVxb"
      },
      "source": [
        "def get_batches(x, y, batch_size=100):\n",
        "    \n",
        "    n_batches = len(x)//batch_size\n",
        "    x, y = x[:n_batches*batch_size], y[:n_batches*batch_size]\n",
        "    for ii in range(0, len(x), batch_size):\n",
        "        yield x[ii:ii+batch_size], y[ii:ii+batch_size]"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYUyt5niRVxg"
      },
      "source": [
        "## Training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yi_h2Xa_RVxi",
        "outputId": "5b1e2d06-bea6-4070-b67d-6661d28eec7f"
      },
      "source": [
        "! mkdir checkpoints"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘checkpoints’: File exists\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKDqsp2QRVxq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d84ff608-20b2-46b8-802f-8317774737b5"
      },
      "source": [
        "epochs = 3\n",
        "\n",
        "with graph.as_default():\n",
        "    saver = tf.compat.v1.train.Saver()\n",
        "\n",
        "with tf.compat.v1.Session(graph=graph) as sess:\n",
        "    sess.run(tf.compat.v1.global_variables_initializer())\n",
        "    iteration = 1\n",
        "    for e in range(epochs):\n",
        "        state = sess.run(initial_state)\n",
        "        \n",
        "        for ii, (x, y) in enumerate(get_batches(train_x, train_y, batch_size), 1):\n",
        "            feed = {inputs_: x,\n",
        "                    labels_: y[:, None],\n",
        "                    keep_prob: 0.5,\n",
        "                    initial_state: state}\n",
        "            loss, state, _ = sess.run([cost, final_state, optimizer], feed_dict=feed)\n",
        "            \n",
        "            if iteration%5==0:\n",
        "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
        "                      \"Iteration: {}\".format(iteration),\n",
        "                      \"Train loss: {}\".format(loss))\n",
        "\n",
        "            if iteration%25==0:\n",
        "                val_acc = []\n",
        "                val_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
        "                for x, y in get_batches(val_x, val_y, batch_size):\n",
        "                    feed = {inputs_: x,\n",
        "                            labels_: y[:, None],\n",
        "                            keep_prob: 1,\n",
        "                            initial_state: val_state}\n",
        "                    batch_acc, val_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
        "                    val_acc.append(batch_acc)\n",
        "                print(\"Val acc: {}\".format(np.mean(val_acc)))\n",
        "            iteration +=1\n",
        "    saver.save(sess, \"checkpoints/sentiment.ckpt\")"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0/3 Iteration: 5 Train loss: [2.49839679e-04 1.86234640e-04 2.34158579e-04 6.31794101e-05\n",
            " 1.05913240e-03 8.72879355e-06 9.66534019e-01 2.85410671e-04\n",
            " 5.84203866e-04 1.14195274e-04 4.55595844e-04 9.41734295e-04\n",
            " 1.01356207e-04 1.98329159e-04 1.86745005e-04 9.61742461e-01\n",
            " 9.83038723e-01 3.90153116e-04 9.58436251e-01 9.70383525e-01\n",
            " 5.27312455e-04 1.97844274e-04 1.01912643e-04 3.66339809e-04\n",
            " 2.22017072e-04 1.17200805e-04 4.10806038e-04 1.48466410e-04\n",
            " 5.08398334e-05 2.35559797e-04 9.15267738e-05 4.98593668e-04\n",
            " 2.78073363e-04 8.46908893e-04 8.21623762e-05 9.75562692e-01\n",
            " 5.21069160e-04 7.00645440e-04 4.57612041e-04 6.35099073e-04\n",
            " 6.06647693e-04 4.93714528e-04 2.75234983e-04 1.05940015e-03\n",
            " 3.25935398e-04 2.71621800e-04 1.67132996e-03 4.15020942e-04\n",
            " 1.62197917e-04 5.63871756e-04 4.05957893e-04 4.21737859e-05\n",
            " 5.66030852e-04 1.92566295e-04 1.22705335e-03 1.12662856e-04\n",
            " 3.77935445e-04 4.80976276e-04 1.55721165e-04 2.33418541e-04\n",
            " 1.07693668e-04 1.45318234e-04 4.43793106e-04 2.98141706e-04\n",
            " 4.43887475e-05 1.58396084e-04 5.11234044e-04 3.62910534e-04\n",
            " 8.08274199e-05 2.23597177e-04 9.84570146e-01 5.15271618e-04\n",
            " 2.09344129e-04 2.77751416e-04 4.30738546e-05 1.59395364e-04\n",
            " 5.09474121e-05 9.73961413e-01 3.81713064e-04 6.55892873e-05\n",
            " 1.04884361e-03 1.09016459e-04 5.06767647e-05 4.48776904e-04\n",
            " 3.80862439e-05 3.61060927e-04 8.35072075e-04 2.94288620e-04\n",
            " 7.43452401e-04 1.06786320e-04 3.14499717e-04 5.79033804e-05\n",
            " 1.18802651e-04 9.71021295e-01 5.89151095e-05 1.14513969e-04\n",
            " 2.24832416e-04 3.63931722e-05 1.42253528e-04 7.74872096e-05\n",
            " 9.81116318e-04 3.19118903e-04 7.55601286e-05 7.97216257e-04\n",
            " 3.89280031e-04 2.67343014e-04 2.81271059e-04 3.36944766e-04\n",
            " 9.02120082e-05 2.16950270e-04 1.48210151e-04 2.64347793e-04\n",
            " 1.09355897e-04 6.90737725e-05 6.10781426e-04 3.09313269e-04\n",
            " 5.06831311e-05 3.58409889e-04 3.15327925e-04 1.74340326e-04\n",
            " 2.90908611e-05 2.32506980e-04 2.25924086e-04 9.78143692e-01\n",
            " 1.73801644e-04 8.34957464e-05 2.47884833e-04 1.28162582e-03\n",
            " 5.15378488e-04 1.20289173e-04 9.82877016e-01 1.37368916e-04\n",
            " 2.67381984e-04 1.47141051e-04 1.67885562e-04 5.11676189e-04\n",
            " 1.12747669e-03 2.80460925e-04 1.77407288e-04 1.71052117e-04\n",
            " 3.48272675e-04 1.45730955e-04 1.21736921e-04 4.42141863e-05\n",
            " 1.06906216e-03 5.15482679e-04 4.32455068e-04 1.69464751e-04\n",
            " 2.11901162e-04 8.37611951e-05 3.06484144e-04 5.18610759e-04\n",
            " 1.74036672e-04 8.49018979e-05 9.06597998e-05 4.78252012e-04\n",
            " 3.77952820e-04 2.39710120e-04 8.16983957e-05 1.68602259e-04\n",
            " 9.78049219e-01 5.90038981e-05 1.74923989e-04 5.81627886e-04\n",
            " 1.71360967e-04 1.53157697e-03 6.88610657e-04 1.56858267e-04\n",
            " 4.17598567e-05 1.28074826e-04 3.01924534e-04 2.30749836e-04\n",
            " 9.43846302e-04 4.42086384e-05 2.22144983e-04 6.19674101e-04\n",
            " 7.74966611e-05 1.66338100e-03 2.01062358e-05 2.86411494e-04\n",
            " 3.57779383e-04 1.04511564e-03 1.92663894e-04 1.22016580e-04\n",
            " 1.85886660e-04 6.19821018e-04 6.01887295e-04 1.19260792e-03\n",
            " 5.14323590e-04 1.27372230e-04 3.26518872e-04 5.27186552e-04\n",
            " 8.26466348e-05 5.12461178e-04 1.55097732e-04 4.52422071e-04\n",
            " 3.63695581e-04 2.56361644e-04 9.81565416e-01 1.73061853e-03\n",
            " 2.47147749e-04 3.50743125e-04 5.43581496e-04 3.34006938e-04\n",
            " 5.38937456e-05 9.63283598e-01 1.36840594e-04 1.83029071e-04\n",
            " 2.85485206e-04 9.55787003e-01 2.10556696e-04 4.55768168e-05\n",
            " 3.58802703e-04 4.64796904e-04 3.46414221e-04 1.65536781e-04\n",
            " 5.07115656e-05 1.56688853e-04 7.16315175e-04 3.67045170e-04\n",
            " 1.68791143e-04 9.08789953e-05 5.63387817e-04 3.11255135e-05\n",
            " 4.44597070e-04 2.96025362e-04 1.85232246e-04 1.86779216e-04\n",
            " 9.61113155e-01 9.07500580e-05 3.76067532e-04 3.73448245e-04\n",
            " 2.09263075e-04 3.59565194e-04 2.15556604e-04 2.08625512e-04\n",
            " 3.48644302e-04 2.08331170e-04 6.10055460e-04 1.58632465e-04\n",
            " 3.92507791e-05 7.10998487e-04 6.47676294e-04 2.43371964e-04\n",
            " 8.33801401e-04 7.60557363e-04 3.10713251e-04 7.56371475e-04\n",
            " 7.62113195e-04 2.88749434e-04 2.54651473e-04 2.59534107e-04\n",
            " 6.86578802e-04 3.33734024e-05 1.00061807e-04 8.59662483e-04\n",
            " 1.28127445e-04 4.41976765e-04 3.37846897e-04 9.57982838e-01\n",
            " 2.51192512e-04 2.54260696e-04 2.83621106e-04 2.53820821e-04\n",
            " 9.83336329e-01 1.02202270e-04 3.79749894e-04 4.41142620e-04\n",
            " 1.73926601e-04 5.87184040e-04 4.19138989e-04 2.62248068e-04\n",
            " 1.16053743e-04 9.83353853e-01 1.01268015e-04 1.53518294e-03\n",
            " 3.69970890e-04 3.29379283e-04 2.74031889e-04 9.66463089e-01\n",
            " 2.98799714e-04 1.23715203e-04 9.78345156e-01 9.66094315e-01\n",
            " 2.03838150e-04 8.85778248e-01 1.09273009e-04 3.17794649e-04\n",
            " 2.81631044e-04 1.27302168e-03 1.13652705e-03 1.21886253e-04\n",
            " 3.90378002e-04 7.76368179e-05 7.31583714e-05 2.23150109e-05\n",
            " 2.25534546e-04 4.57735732e-04 1.89567718e-03 1.82989563e-04\n",
            " 1.56217662e-04 6.15970290e-04 2.82200490e-04 9.68726814e-01\n",
            " 1.26413433e-04 7.11869739e-04 1.42500328e-04 6.00556414e-05\n",
            " 7.51505839e-04 1.87646132e-04 1.05783474e-04 3.64540640e-04\n",
            " 4.87755606e-04 1.25268346e-03 1.66929283e-04 2.05926299e-05\n",
            " 7.89254089e-04 5.93675322e-05 2.09657545e-03 2.35112675e-04\n",
            " 1.51600630e-04 1.46163715e-04 7.45176731e-05 2.05443706e-04\n",
            " 1.42664736e-04 2.83650210e-04 9.04431363e-05 9.48505521e-01\n",
            " 1.53290326e-04 9.46436107e-01 1.55635629e-04 9.73734617e-01\n",
            " 5.72711171e-04 3.72511247e-04 1.56664231e-04 3.12520919e-04\n",
            " 8.40043474e-04 1.07610183e-04 8.69976182e-04 1.82855743e-04\n",
            " 2.89204356e-04 2.31646176e-04 9.86304045e-01 8.40739813e-04\n",
            " 4.97538858e-05 9.62732553e-01 9.64017749e-01 9.61046755e-01\n",
            " 1.42555829e-04 9.91231645e-05 3.12513403e-05 9.82609272e-01\n",
            " 4.19793301e-04 5.78108535e-04 2.97069229e-04 9.69916224e-01\n",
            " 1.77398557e-04 2.01661212e-04 9.74453390e-01 2.05475328e-04\n",
            " 2.47326767e-04 1.02738057e-04 2.79722764e-04 1.44175166e-04\n",
            " 3.16157239e-04 1.56465103e-04 3.96759744e-04 1.23350168e-04\n",
            " 4.88163787e-04 8.38202948e-04 6.30756374e-04 9.82016146e-01\n",
            " 4.31634893e-04 2.89939722e-04 9.47707176e-01 2.40768859e-04\n",
            " 2.40134817e-04 8.92058655e-04 1.54641559e-04 8.60515516e-04\n",
            " 2.19401307e-04 2.10419195e-04 2.19016540e-04 1.91074578e-04\n",
            " 4.00872319e-04 9.80672240e-01 2.42638853e-04 9.18069782e-05\n",
            " 1.34341317e-04 8.41013971e-05 2.17328823e-04 1.36586212e-04\n",
            " 9.76973176e-01 9.41848484e-05 1.30640707e-04 1.76849615e-04\n",
            " 9.82895494e-01 2.17648776e-04 3.83737352e-04 1.93631731e-03\n",
            " 9.26900923e-01 9.70732093e-01 3.46257817e-04 5.82303735e-04\n",
            " 4.04654711e-04 5.35645057e-04 1.33112349e-04 2.18209287e-04\n",
            " 2.29516503e-04 2.84462905e-04 2.15371998e-04 1.19401753e-04\n",
            " 9.59248006e-01 6.22918596e-05 2.39014815e-04 9.60703552e-01\n",
            " 1.82733260e-04 3.20581428e-04 7.83073483e-05 1.99992047e-03\n",
            " 8.56747356e-05 8.21915528e-05 2.19192996e-04 6.58584395e-05\n",
            " 3.35676799e-04 9.82353210e-01 9.10961826e-05 4.91807936e-04\n",
            " 2.59596534e-04 5.50440163e-04 4.59612231e-04 5.98951650e-04\n",
            " 4.69023915e-04 1.40097764e-04 2.99793737e-05 6.46789151e-04\n",
            " 6.84026105e-04 5.11312217e-04 2.94001366e-04 4.79914015e-03\n",
            " 1.45127648e-03 2.49196601e-04 5.57709194e-04 5.87710856e-05\n",
            " 1.05211814e-03 1.47418090e-04 1.26343090e-04 8.00949419e-05\n",
            " 7.60718540e-05 1.20931982e-04 9.81727421e-01 1.85678684e-04\n",
            " 3.96476040e-04 5.58358079e-05 3.88055574e-04 2.15813954e-04\n",
            " 8.47547708e-05 9.88545289e-05 1.40072068e-03 2.39235102e-04\n",
            " 2.72020785e-04 9.12936957e-05 9.77149427e-01 5.61967099e-05\n",
            " 4.23644087e-04 1.00540114e-03 3.21312895e-04 9.13894037e-05\n",
            " 4.81746538e-04 2.69076641e-04 9.01595806e-04 1.14712420e-04\n",
            " 5.45485585e-04 3.29834875e-04 1.29174659e-04 1.09674635e-04\n",
            " 3.03750101e-04 9.68173146e-01 2.76018720e-04 9.63293195e-01\n",
            " 3.30015282e-05 2.25830037e-04 9.62948501e-01 1.42758727e-04\n",
            " 1.48919222e-04 5.35080966e-04 2.45242700e-04 5.09878373e-05\n",
            " 1.34423535e-04 5.70539327e-04 6.37617544e-04 1.71730222e-04\n",
            " 6.72603637e-05 8.47009534e-04 6.59281141e-05 1.67511214e-04\n",
            " 7.34374989e-05 2.16504723e-05 6.07321737e-04 4.00513207e-04]\n",
            "Epoch: 0/3 Iteration: 10 Train loss: [8.94354831e-04 1.24383450e-03 2.03938223e-03 1.28425809e-03\n",
            " 1.97068701e-04 2.01431359e-03 1.55303022e-03 9.40451920e-01\n",
            " 7.57042086e-04 5.64881368e-04 9.57061768e-01 9.61002231e-01\n",
            " 1.31772051e-03 4.01859870e-04 3.89841181e-04 3.91393527e-03\n",
            " 4.02194506e-04 1.59982534e-03 1.75730686e-03 1.31320232e-03\n",
            " 9.76809621e-01 2.31547048e-03 9.25286829e-01 9.20337439e-01\n",
            " 4.99376561e-04 9.59922493e-01 3.95094597e-04 1.08655985e-03\n",
            " 1.07456103e-03 3.80263460e-04 9.63266730e-01 3.12087970e-04\n",
            " 5.39773493e-04 4.20909026e-04 2.19148584e-03 9.39370632e-01\n",
            " 9.59127545e-01 9.56692576e-01 9.49275613e-01 6.67404500e-04\n",
            " 5.73344645e-04 1.14383700e-03 3.32192431e-04 9.55952525e-01\n",
            " 1.26623188e-03 9.30525780e-01 9.54840004e-01 4.82082181e-03\n",
            " 5.34591614e-04 9.68766034e-01 9.71569121e-01 2.39664968e-03\n",
            " 9.60463107e-01 2.77430663e-04 1.87010062e-03 5.33292827e-04\n",
            " 9.39162433e-01 1.55585076e-04 8.54025900e-01 1.85541445e-04\n",
            " 9.65800226e-01 9.08971939e-04 4.86055855e-03 1.07253192e-03\n",
            " 1.12049654e-03 3.31037532e-04 9.16032255e-01 9.33732688e-01\n",
            " 1.49211183e-03 1.49147864e-03 3.78502271e-04 1.26757903e-03\n",
            " 1.27794326e-03 2.97101069e-04 8.37990665e-04 9.72485781e-01\n",
            " 9.53045309e-01 9.68189776e-01 9.71586645e-01 1.10312644e-03\n",
            " 5.92781114e-04 6.63578860e-04 4.50325024e-04 9.61627781e-01\n",
            " 9.38236597e-04 1.59052201e-03 9.46617723e-01 4.37292707e-04\n",
            " 1.20705611e-03 5.43336105e-03 9.50993657e-01 1.94339233e-03\n",
            " 1.21775898e-03 3.76992801e-04 4.08581342e-04 1.61897612e-03\n",
            " 9.14362026e-04 9.47532177e-01 1.21978368e-03 5.67428477e-04\n",
            " 9.17628706e-01 9.63394701e-01 9.60892379e-01 1.64022704e-03\n",
            " 9.30278063e-01 9.79678240e-03 1.33416348e-03 9.21804011e-01\n",
            " 6.09844923e-04 9.29638922e-01 2.61175825e-04 2.55043502e-04\n",
            " 2.91461067e-04 9.20641352e-04 9.36653972e-01 1.05779630e-03\n",
            " 9.68222618e-01 3.38264450e-04 1.17035036e-03 5.45240589e-04\n",
            " 9.24609121e-05 9.75338638e-01 3.70308029e-04 9.73401546e-01\n",
            " 9.62231100e-01 2.81201489e-03 1.22002755e-04 8.71172058e-04\n",
            " 9.33632313e-04 9.65408564e-01 6.62053528e-04 9.75534320e-01\n",
            " 1.03128213e-03 9.83344018e-01 7.89836922e-04 6.18273299e-03\n",
            " 1.42186740e-03 2.08114434e-04 1.32806587e-03 9.27437901e-01\n",
            " 9.38744724e-01 1.14027166e-03 5.01364528e-04 9.13837634e-04\n",
            " 1.79390819e-03 8.76480639e-01 1.69755635e-03 1.66976836e-03\n",
            " 9.03575361e-01 3.96618474e-04 4.31970548e-04 9.46372092e-01\n",
            " 8.29928205e-04 2.91668461e-03 1.06538390e-03 1.55029455e-04\n",
            " 9.78460968e-01 6.35371357e-03 3.92593996e-04 4.47383965e-04\n",
            " 4.89343132e-04 2.37780681e-04 9.49609697e-01 8.06433265e-04\n",
            " 2.49609846e-04 9.51817334e-01 9.41657841e-01 9.54006970e-01\n",
            " 9.35237825e-01 1.28211873e-03 8.25803669e-04 6.33914431e-04\n",
            " 2.34074146e-03 9.65846181e-01 5.18846966e-04 5.88350231e-04\n",
            " 9.65990424e-01 1.61796605e-04 4.53372137e-04 9.61653769e-01\n",
            " 6.66503969e-04 1.40387172e-04 1.19700890e-04 7.69053062e-04\n",
            " 2.13570325e-04 9.27911282e-01 1.38626934e-03 2.12171534e-03\n",
            " 9.78813827e-01 2.30600382e-03 1.03493757e-03 2.41610827e-03\n",
            " 9.61471140e-01 4.57927563e-05 1.67340424e-03 8.86766553e-01\n",
            " 7.08123145e-04 1.38522196e-03 1.33994129e-03 1.97680807e-03\n",
            " 9.43379104e-01 7.13276269e-04 6.50519039e-04 6.18204591e-04\n",
            " 4.64313867e-04 2.11757157e-04 4.71077336e-04 9.60241616e-01\n",
            " 2.11324566e-03 9.54383314e-01 9.44512069e-01 3.14290461e-04\n",
            " 2.40267324e-03 9.27924179e-04 9.93595459e-04 1.00812642e-03\n",
            " 1.05116912e-03 9.62778807e-01 8.22793518e-04 4.96919442e-04\n",
            " 1.43145805e-03 2.16882350e-03 9.47715044e-01 9.38427389e-01\n",
            " 3.53785395e-03 2.76442704e-04 1.95551271e-04 1.98120193e-04\n",
            " 9.26927745e-01 9.46308672e-01 6.71322981e-04 2.41253729e-04\n",
            " 1.00694213e-03 7.22284254e-04 2.01070379e-03 1.05887442e-03\n",
            " 1.10298989e-03 1.75524416e-04 3.33849364e-03 6.09173905e-04\n",
            " 4.00789984e-04 9.37302709e-01 2.87034200e-04 3.62314633e-04\n",
            " 5.30790654e-04 2.08633253e-04 5.83976274e-04 2.34335475e-03\n",
            " 1.64457271e-03 5.75160095e-03 2.48013879e-03 8.90279305e-04\n",
            " 5.84702415e-04 1.34203190e-04 2.71796685e-04 6.96516305e-04\n",
            " 1.86065538e-03 4.26995015e-04 6.25383342e-04 1.08037773e-03\n",
            " 1.85032643e-03 2.43732822e-03 1.71959153e-04 9.72197533e-01\n",
            " 4.86005069e-04 2.52352009e-04 2.17994652e-03 1.13581587e-03\n",
            " 8.35218467e-04 1.81592521e-04 4.18780313e-04 1.59334962e-03\n",
            " 9.61319923e-01 6.46974135e-04 9.48956490e-01 1.74216009e-04\n",
            " 9.59119856e-01 9.52878416e-01 1.85189259e-04 4.00568068e-04\n",
            " 3.02975648e-04 1.84707937e-03 3.30917467e-03 5.67312061e-04\n",
            " 1.45565311e-03 2.26317905e-03 9.26393926e-01 9.42898691e-01\n",
            " 9.65005994e-01 1.95476270e-04 9.65316117e-01 5.34714316e-04\n",
            " 4.64126351e-04 9.64940875e-04 8.95383120e-01 5.58010419e-04\n",
            " 6.51941227e-04 5.33778861e-04 3.08736984e-04 1.07650796e-03\n",
            " 6.88280677e-04 1.42579316e-04 8.96398793e-04 6.15519180e-04\n",
            " 9.62654114e-01 2.28938938e-04 9.28858399e-01 7.29763589e-04\n",
            " 6.91609166e-04 2.85446935e-04 9.53656256e-01 5.18716639e-04\n",
            " 2.03390280e-03 2.36900034e-03 9.74538207e-01 1.17487485e-04\n",
            " 8.14027328e-04 4.78495815e-04 9.42694128e-01 6.13242504e-04\n",
            " 7.80159389e-05 1.01198512e-03 9.20851529e-01 3.09161289e-04\n",
            " 9.13450956e-01 3.11641692e-04 5.70547883e-04 9.44873095e-01\n",
            " 1.97592843e-03 4.16770112e-04 2.37044122e-04 1.45163306e-03\n",
            " 4.58339113e-04 9.09983995e-04 9.38730180e-01 1.54927187e-03\n",
            " 1.60776929e-03 4.25365841e-04 2.58154178e-04 3.28193681e-04\n",
            " 3.66762019e-04 1.36035983e-03 1.20608089e-03 1.80008035e-04\n",
            " 4.77758120e-04 5.15099789e-04 8.62075889e-04 9.53162849e-01\n",
            " 2.36612046e-03 7.83854630e-04 6.74816198e-04 4.16275027e-04\n",
            " 9.52299476e-01 3.75273870e-04 3.20775202e-03 5.90662821e-04\n",
            " 2.82188470e-04 3.23867222e-04 3.51233524e-03 9.12401974e-01\n",
            " 9.37592149e-01 4.21601627e-03 6.99276628e-04 9.49936867e-01\n",
            " 9.21393633e-01 1.14032801e-03 4.94107953e-04 9.68371153e-01\n",
            " 3.23655480e-03 1.78623176e-03 7.54007895e-04 2.10803188e-03\n",
            " 9.77386296e-01 1.97206717e-03 1.50884851e-03 9.51682210e-01\n",
            " 8.94218624e-01 5.29240002e-04 9.07148838e-01 2.87798146e-04\n",
            " 1.35894676e-04 1.76546950e-04 2.26117641e-04 5.98038838e-04\n",
            " 9.52590346e-01 9.17758405e-01 9.25780535e-01 9.48251247e-01\n",
            " 1.29151624e-04 9.15890574e-01 4.77726862e-04 9.64340866e-01\n",
            " 9.49379265e-01 7.45830359e-04 2.80884327e-04 5.55515464e-04\n",
            " 9.34994280e-01 1.27177581e-03 9.40809846e-01 9.62250531e-01\n",
            " 2.08501704e-03 9.66326833e-01 1.14900549e-03 9.52351391e-01\n",
            " 7.70266808e-04 9.82188642e-01 9.51098859e-01 1.57660840e-03\n",
            " 1.87742815e-03 1.03221647e-03 5.01707545e-04 4.31958149e-04\n",
            " 2.36183149e-03 1.21638656e-03 2.18649744e-04 8.55998194e-04\n",
            " 1.69946998e-03 8.82303109e-04 5.34019840e-04 4.09562665e-04\n",
            " 2.67088704e-04 2.89930846e-03 9.20300603e-01 9.56456363e-01\n",
            " 9.14321184e-01 2.70779990e-03 3.14232340e-04 9.38058197e-01\n",
            " 9.44166541e-01 1.20049226e-03 1.53905747e-03 1.67085719e-03\n",
            " 4.15028248e-04 9.12376881e-01 2.82643246e-04 3.58257629e-03\n",
            " 5.41546091e-04 1.85688434e-04 9.67502534e-01 1.74274232e-04\n",
            " 9.34989870e-01 9.18600650e-04 3.45691282e-04 7.26183702e-04\n",
            " 4.05434432e-04 1.03509671e-03 9.20287669e-01 4.07476956e-03\n",
            " 2.38204579e-04 2.84312619e-03 7.46971869e-04 8.32435384e-04\n",
            " 2.72894744e-03 8.49000411e-04 1.75641500e-03 2.65374430e-03\n",
            " 1.10780145e-03 7.91730941e-04 9.62980092e-01 1.24264287e-03\n",
            " 4.59179137e-04 9.50294375e-01 4.81382915e-04 2.74376362e-04\n",
            " 9.39060748e-01 1.40426983e-03 3.48575297e-04 4.46475460e-04\n",
            " 9.40806985e-01 1.99471557e-04 1.66873331e-03 7.05834653e-04\n",
            " 4.80330753e-04 8.96832407e-01 9.40919936e-01 1.18778588e-03\n",
            " 2.51413253e-03 1.46548473e-03 4.91901767e-04 9.28142548e-01\n",
            " 9.30006444e-01 1.79145276e-03 9.75301206e-01 8.07237462e-04\n",
            " 3.30987648e-04 2.76664668e-03 2.83950428e-03 9.71789718e-01\n",
            " 8.83337379e-01 1.48568815e-03 8.26406700e-04 1.40769384e-03\n",
            " 1.91762345e-04 4.09032073e-04 7.11562810e-04 1.17527589e-03\n",
            " 6.88072701e-04 9.28165197e-01 8.09908612e-04 7.63156801e-04]\n",
            "Epoch: 0/3 Iteration: 15 Train loss: [0.00689905 0.10014837 0.03352772 0.03293447 0.01391309 0.65190184\n",
            " 0.02188111 0.01990028 0.08409791 0.00910122 0.02876595 0.0332434\n",
            " 0.7628642  0.02030117 0.00988516 0.00844137 0.01043008 0.11958684\n",
            " 0.02427174 0.7474463  0.00845092 0.03253792 0.02565703 0.04061987\n",
            " 0.02583288 0.75807416 0.6494763  0.04067219 0.01889276 0.01897957\n",
            " 0.03792952 0.02226481 0.03201911 0.01899431 0.04624189 0.03485168\n",
            " 0.02145647 0.00953457 0.67245954 0.01451193 0.70965636 0.01255994\n",
            " 0.02483075 0.01681983 0.03627774 0.01592223 0.6564246  0.01672552\n",
            " 0.0278011  0.04421204 0.0806525  0.01762222 0.01630794 0.00990631\n",
            " 0.00539308 0.00842205 0.5999121  0.04467421 0.01120533 0.06135675\n",
            " 0.00440613 0.02175979 0.04137152 0.02290322 0.7111848  0.82869494\n",
            " 0.01120281 0.01062782 0.00657524 0.01121332 0.01793245 0.04979392\n",
            " 0.04034704 0.02095477 0.01787271 0.03310707 0.00436171 0.59334195\n",
            " 0.00662603 0.04031694 0.03362443 0.01315828 0.01425933 0.01838119\n",
            " 0.8850559  0.01152649 0.00901822 0.04208148 0.06570089 0.04262014\n",
            " 0.7991114  0.01053095 0.01925361 0.02686974 0.02830081 0.02825545\n",
            " 0.02319269 0.05667001 0.6465238  0.04199134 0.01181351 0.01203119\n",
            " 0.04079561 0.02119208 0.02456179 0.04486958 0.0220212  0.0237052\n",
            " 0.00776857 0.02083482 0.0094405  0.0115267  0.77453995 0.0148672\n",
            " 0.00786676 0.0174733  0.0185928  0.00592117 0.02985668 0.01558835\n",
            " 0.07011598 0.75814724 0.03433484 0.0458964  0.6390554  0.02113993\n",
            " 0.02413517 0.03113406 0.6838512  0.01519362 0.02945213 0.01215523\n",
            " 0.02009344 0.7480691  0.01787485 0.67300344 0.01949201 0.0418623\n",
            " 0.00659118 0.7629604  0.01078903 0.70633864 0.01489678 0.01411654\n",
            " 0.68027204 0.00473959 0.8008621  0.07575509 0.05109175 0.01286611\n",
            " 0.01197778 0.00835313 0.0521566  0.01826312 0.01212651 0.01164878\n",
            " 0.02252503 0.03542939 0.02389356 0.01487603 0.655992   0.03857471\n",
            " 0.6430518  0.01250778 0.04461727 0.7793617  0.7188438  0.02173387\n",
            " 0.6564669  0.03663901 0.11813739 0.58722186 0.02297311 0.77221745\n",
            " 0.00878135 0.02785928 0.7291806  0.45358396 0.7459626  0.00233975\n",
            " 0.04392791 0.7336465  0.00826199 0.01757916 0.01241914 0.04781785\n",
            " 0.04618979 0.00330156 0.6225805  0.02192691 0.02504324 0.01308628\n",
            " 0.7921409  0.01220717 0.0146994  0.03445902 0.01305235 0.01474391\n",
            " 0.8231892  0.01131188 0.01179044 0.46803045 0.01200253 0.03497105\n",
            " 0.02681609 0.01813141 0.80807936 0.03027923 0.02200798 0.051098\n",
            " 0.01222832 0.05412216 0.00551406 0.5965414  0.7642515  0.69160604\n",
            " 0.00444002 0.6514332  0.00974158 0.8697489  0.01774678 0.02607619\n",
            " 0.04928503 0.01821422 0.76658577 0.01179332 0.7844983  0.02945608\n",
            " 0.02541766 0.04067784 0.02530934 0.03120543 0.03808992 0.01016121\n",
            " 0.01909156 0.02190347 0.3649582  0.02219603 0.0063912  0.04139793\n",
            " 0.00552703 0.01345513 0.02719677 0.799105   0.01497208 0.01518537\n",
            " 0.0157038  0.01008679 0.73384434 0.02498451 0.02242324 0.02287399\n",
            " 0.51797175 0.02492395 0.01599292 0.70660144 0.00950835 0.05619546\n",
            " 0.0161486  0.00508817 0.6791753  0.0228435  0.870707   0.07485229\n",
            " 0.00247782 0.00688045 0.1118606  0.02050292 0.7458151  0.01095146\n",
            " 0.02686044 0.02072192 0.01423197 0.02916037 0.68435895 0.6558468\n",
            " 0.04432803 0.01548882 0.00848402 0.03366517 0.02593938 0.01933903\n",
            " 0.00876743 0.7116526  0.69261634 0.01622105 0.08059216 0.00423323\n",
            " 0.01654243 0.8432434  0.03240971 0.02229698 0.03556474 0.64108527\n",
            " 0.76542974 0.00760238 0.02353063 0.0665575  0.0149734  0.00584944\n",
            " 0.03780283 0.01506065 0.00888307 0.02036791 0.57818043 0.8628971\n",
            " 0.01546423 0.02220663 0.02806816 0.06278099 0.7099683  0.7457221\n",
            " 0.01638955 0.00375858 0.00828259 0.64227915 0.01449752 0.75542325\n",
            " 0.04602121 0.01938648 0.7221583  0.01602839 0.03146182 0.02782818\n",
            " 0.02326516 0.06451655 0.02377945 0.01214951 0.0356329  0.07576142\n",
            " 0.01336022 0.00977246 0.03227532 0.03396816 0.00824146 0.02676907\n",
            " 0.03882071 0.02730332 0.00959903 0.03587249 0.01498365 0.01794124\n",
            " 0.01452783 0.7290191  0.00819824 0.05229856 0.02205443 0.01238404\n",
            " 0.02988634 0.04180121 0.0133654  0.02224036 0.7671263  0.03135416\n",
            " 0.7736516  0.11129969 0.00900013 0.01287028 0.01873558 0.01987143\n",
            " 0.05139261 0.05124054 0.02436808 0.00756679 0.03835732 0.04216787\n",
            " 0.7721847  0.01800315 0.03602852 0.7236397  0.024491   0.03279532\n",
            " 0.04333626 0.00921791 0.01539347 0.06125162 0.77235657 0.04124725\n",
            " 0.025739   0.03634866 0.01143251 0.0244736  0.0291156  0.07528437\n",
            " 0.0175517  0.7715016  0.05194599 0.01994065 0.01994924 0.01919748\n",
            " 0.02382768 0.04538571 0.01618917 0.00797162 0.01937988 0.04686506\n",
            " 0.03609922 0.00869603 0.07278448 0.02744766 0.02211249 0.02703029\n",
            " 0.01830813 0.04517826 0.03841112 0.01466755 0.01326854 0.02106281\n",
            " 0.00913308 0.01108027 0.02661326 0.03825456 0.8659854  0.0494222\n",
            " 0.00976983 0.01427307 0.01451258 0.13906698 0.03579104 0.01385508\n",
            " 0.03863373 0.01839109 0.04610278 0.02268354 0.08105484 0.03113481\n",
            " 0.04315303 0.02067398 0.12912953 0.02400533 0.01934251 0.01595378\n",
            " 0.7584002  0.0111446  0.7372488  0.01329737 0.07767311 0.01544544\n",
            " 0.73889893 0.04540214 0.02163248 0.04916511 0.00397765 0.7302769\n",
            " 0.01564966 0.04846921 0.08066452 0.70721257 0.0130606  0.03819778\n",
            " 0.01479956 0.09362352 0.02806465 0.6155474  0.01189191 0.0290781\n",
            " 0.05209825 0.01113813 0.01697079 0.02296418 0.67420167 0.00630937\n",
            " 0.0525508  0.01834825 0.00789158 0.01395284 0.00555797 0.73311436\n",
            " 0.65778345 0.76895016 0.06341834 0.03857375 0.01925373 0.01443528\n",
            " 0.01582417 0.02788114 0.02435515 0.0271475  0.02036648 0.72680336\n",
            " 0.07608224 0.6018157  0.5797176  0.75752634 0.00862653 0.7967537\n",
            " 0.01718573 0.07668014 0.00598182 0.00418237 0.02139257 0.03043125\n",
            " 0.04335028 0.0442421  0.08371603 0.0238097  0.00151816 0.05579229\n",
            " 0.03778036 0.04704011]\n",
            "Epoch: 0/3 Iteration: 20 Train loss: [0.44465575 0.14143777 0.58386314 0.47500163 0.01206892 0.12120453\n",
            " 0.07877915 0.07733455 0.09309381 0.15301915 0.08949639 0.08900575\n",
            " 0.50496703 0.04644934 0.08043388 0.03354906 0.0906615  0.07394977\n",
            " 0.12441257 0.10832098 0.07784906 0.09948912 0.14709    0.0496863\n",
            " 0.41556114 0.21952578 0.16995658 0.07186528 0.2135181  0.09068348\n",
            " 0.09235114 0.09718007 0.15211903 0.04842741 0.2507154  0.1013986\n",
            " 0.09430829 0.09368633 0.02495078 0.13748646 0.09246773 0.1177057\n",
            " 0.05998954 0.08204071 0.11326034 0.11671485 0.09414263 0.08140317\n",
            " 0.19524007 0.09030285 0.19365041 0.09627103 0.04423827 0.04311694\n",
            " 0.05490623 0.08880281 0.05938188 0.09010411 0.19371945 0.38042462\n",
            " 0.104203   0.5054269  0.06879192 0.1039409  0.1849048  0.1238941\n",
            " 0.12471826 0.03085707 0.04745791 0.03786374 0.02262172 0.03542137\n",
            " 0.1770107  0.1424094  0.10631646 0.17310476 0.05933012 0.16624556\n",
            " 0.46609172 0.12708738 0.07657224 0.1006638  0.05193954 0.09563005\n",
            " 0.1256489  0.07478117 0.09323877 0.5334935  0.4837425  0.05294653\n",
            " 0.0664453  0.16022508 0.14598516 0.18627098 0.5701978  0.07220644\n",
            " 0.07506884 0.02622361 0.08635019 0.13520512 0.06821181 0.10921497\n",
            " 0.03607921 0.12052618 0.1148761  0.08345578 0.42933393 0.16165018\n",
            " 0.08696112 0.05055993 0.08165386 0.05088897 0.10064103 0.17691943\n",
            " 0.08911388 0.05224992 0.11885802 0.15663971 0.16120143 0.13808446\n",
            " 0.13518526 0.11292061 0.1052933  0.12860934 0.16841155 0.44562638\n",
            " 0.13649347 0.22578879 0.05735056 0.31465787 0.11619136 0.11150798\n",
            " 0.06702528 0.14173314 0.07315089 0.15295218 0.04717283 0.06468149\n",
            " 0.18091777 0.16143185 0.20694217 0.03207093 0.1250267  0.07974731\n",
            " 0.04545997 0.07024237 0.05396884 0.06850951 0.10430674 0.15689805\n",
            " 0.05185569 0.06000354 0.18613996 0.13389906 0.07345497 0.15713531\n",
            " 0.07051371 0.04099054 0.516601   0.21746157 0.17863074 0.14045632\n",
            " 0.10807446 0.01733926 0.19851273 0.09391025 0.05529469 0.05037195\n",
            " 0.11279821 0.06137161 0.7584685  0.01972017 0.06943817 0.04491533\n",
            " 0.16953199 0.08923175 0.15631668 0.05392636 0.10811055 0.4965394\n",
            " 0.20995036 0.22620206 0.14037424 0.11646576 0.05191325 0.10696184\n",
            " 0.08678193 0.13724655 0.09181035 0.04642841 0.09678295 0.03927507\n",
            " 0.10842834 0.08160667 0.11919736 0.07907084 0.08938403 0.07902145\n",
            " 0.12246764 0.06597757 0.07535937 0.14532737 0.07682028 0.13442913\n",
            " 0.16053163 0.09797368 0.13360043 0.06510054 0.10186633 0.08045985\n",
            " 0.193933   0.04838974 0.09574541 0.09124828 0.54041445 0.05189864\n",
            " 0.1788111  0.08252978 0.10740383 0.12433852 0.03971116 0.64128965\n",
            " 0.06891038 0.04852593 0.10565707 0.06904753 0.1219072  0.2689541\n",
            " 0.07538898 0.03581563 0.06379379 0.03024751 0.08720866 0.03002312\n",
            " 0.07123494 0.11136556 0.1784455  0.08414489 0.06395739 0.02194499\n",
            " 0.10636993 0.10225943 0.02921313 0.07441764 0.13532841 0.10458907\n",
            " 0.05655203 0.12824984 0.18287241 0.05404036 0.12842987 0.10305354\n",
            " 0.04063208 0.05836204 0.11324376 0.67297614 0.08364227 0.13625847\n",
            " 0.4912914  0.03080211 0.0723633  0.09277245 0.1349915  0.50673515\n",
            " 0.06048859 0.04802036 0.07272076 0.05730608 0.05294668 0.05896965\n",
            " 0.06347279 0.12221471 0.39998913 0.12580809 0.06297837 0.57544285\n",
            " 0.13339186 0.14771038 0.08674186 0.15792033 0.05531198 0.12580484\n",
            " 0.05051913 0.10278641 0.09404726 0.06431644 0.1172001  0.14030127\n",
            " 0.04048352 0.10992987 0.14334936 0.13605614 0.06500006 0.01717943\n",
            " 0.06196361 0.5144104  0.07919141 0.1025087  0.07654938 0.15108567\n",
            " 0.08680686 0.5447099  0.12989426 0.07465798 0.05985135 0.09532905\n",
            " 0.19011226 0.05508518 0.01588287 0.03381989 0.10174585 0.04680666\n",
            " 0.07208791 0.16508524 0.11492309 0.04529348 0.19241093 0.22833335\n",
            " 0.11240019 0.11702398 0.0712604  0.06229828 0.1101016  0.06939711\n",
            " 0.05601728 0.11337967 0.08640693 0.17101608 0.07067591 0.13311194\n",
            " 0.10740928 0.09481145 0.11535224 0.06179189 0.02019493 0.09699152\n",
            " 0.09732528 0.18939307 0.20803706 0.08809676 0.10635298 0.05174972\n",
            " 0.09803425 0.07683586 0.07255091 0.09853116 0.041176   0.09859037\n",
            " 0.17881817 0.06785495 0.05227474 0.15584323 0.16237162 0.05959626\n",
            " 0.09932522 0.15426546 0.06742103 0.06181567 0.06877141 0.17190138\n",
            " 0.08584358 0.6995678  0.12554024 0.14804123 0.10805455 0.09398962\n",
            " 0.1221905  0.07253914 0.1965715  0.04260049 0.0872815  0.03523098\n",
            " 0.0989484  0.05076798 0.06850026 0.04224893 0.02672828 0.1280438\n",
            " 0.19823818 0.06947012 0.06566331 0.0385967  0.05083198 0.0784105\n",
            " 0.11266826 0.11481643 0.10484476 0.06664375 0.07184554 0.39746767\n",
            " 0.08003271 0.25647342 0.02172777 0.11507796 0.17009276 0.08241626\n",
            " 0.0660454  0.12003659 0.03854936 0.04817196 0.09897476 0.0260628\n",
            " 0.06188095 0.18652166 0.0342439  0.04196562 0.11196724 0.07740431\n",
            " 0.08617967 0.17161568 0.08894534 0.14441252 0.11531484 0.19513302\n",
            " 0.17066407 0.05783119 0.02616986 0.03678994 0.09855203 0.06436999\n",
            " 0.10880274 0.16320132 0.05958231 0.05387764 0.11884171 0.44759357\n",
            " 0.1473938  0.05267246 0.15067174 0.12749837 0.10484824 0.03659941\n",
            " 0.02255785 0.06948147 0.05870203 0.07649551 0.10733704 0.01830816\n",
            " 0.0727549  0.06342532 0.08099415 0.06449487 0.19324812 0.37617347\n",
            " 0.07907265 0.14746869 0.07378515 0.01878296 0.15871212 0.0966512\n",
            " 0.06101781 0.02577719 0.10515042 0.08137783 0.03998721 0.15619667\n",
            " 0.03386907 0.05726444 0.06453115 0.07365035 0.09105652 0.18237546\n",
            " 0.0600659  0.10321341 0.0830166  0.07908971 0.05271726 0.05933734\n",
            " 0.14011866 0.21467847 0.06889124 0.04763253 0.10479509 0.14230482\n",
            " 0.10675161 0.12040096 0.08914229 0.06291141 0.09143247 0.08700512\n",
            " 0.09789366 0.0177361  0.15880087 0.20176435 0.11543585 0.07052267\n",
            " 0.14338605 0.09500036 0.03819218 0.06163516 0.0662227  0.08887085\n",
            " 0.06125982 0.11023721 0.07154958 0.07684898 0.09495708 0.40829504\n",
            " 0.06948403 0.05449581]\n",
            "Epoch: 0/3 Iteration: 25 Train loss: [0.00320423 0.01133001 0.75424016 0.6645819  0.00596475 0.85149217\n",
            " 0.00653965 0.00636349 0.00468094 0.00423746 0.00114874 0.00165413\n",
            " 0.7767668  0.00161282 0.01567339 0.01377305 0.87457603 0.00479493\n",
            " 0.00249632 0.00731435 0.00720315 0.00298686 0.00587643 0.00575863\n",
            " 0.879172   0.01951212 0.00732597 0.01403119 0.00741756 0.00208469\n",
            " 0.04067348 0.01701353 0.01092272 0.6971934  0.01096974 0.00123356\n",
            " 0.8420244  0.01697317 0.00567456 0.01108099 0.01728228 0.00380556\n",
            " 0.00296996 0.00948139 0.00932005 0.00336906 0.0017221  0.01151287\n",
            " 0.02160395 0.01708735 0.01108035 0.00475053 0.01371838 0.0048727\n",
            " 0.00258988 0.01178133 0.8603443  0.01133188 0.00825281 0.00450643\n",
            " 0.01272861 0.00680648 0.00724765 0.00260358 0.8312295  0.00722925\n",
            " 0.01065762 0.00814227 0.01125764 0.00439831 0.00637668 0.89538515\n",
            " 0.00475572 0.8416384  0.63907975 0.00211129 0.80332476 0.0032286\n",
            " 0.00281936 0.00246007 0.00581495 0.01541864 0.01578352 0.00587101\n",
            " 0.00732551 0.8341037  0.00846219 0.00302228 0.0091191  0.7714483\n",
            " 0.00594294 0.82089174 0.7647991  0.01535698 0.00957526 0.00185116\n",
            " 0.01286826 0.00280694 0.00608498 0.7728323  0.00333822 0.01039517\n",
            " 0.8020959  0.00379006 0.0143592  0.01084388 0.00210268 0.00249456\n",
            " 0.03222204 0.00618259 0.01570508 0.03023046 0.01333251 0.77762014\n",
            " 0.00950788 0.00505969 0.00611108 0.01138389 0.00494248 0.00590753\n",
            " 0.00303651 0.00559595 0.01293903 0.8561833  0.0074401  0.03461789\n",
            " 0.00726717 0.00608734 0.00686425 0.00848683 0.8246714  0.00708378\n",
            " 0.00181512 0.00576586 0.84049296 0.00513026 0.00924264 0.8266559\n",
            " 0.8490743  0.01757045 0.0163491  0.00264663 0.00731876 0.00212275\n",
            " 0.0135257  0.00987751 0.02305795 0.00632053 0.0056465  0.00803829\n",
            " 0.01110785 0.02791354 0.00736644 0.00715758 0.00460104 0.00174971\n",
            " 0.7940489  0.88594455 0.852376   0.79353994 0.00647739 0.02116098\n",
            " 0.02044857 0.88753015 0.00613607 0.7088215  0.7799326  0.00837791\n",
            " 0.01419611 0.02598279 0.01637266 0.00209922 0.7866216  0.85725635\n",
            " 0.00165138 0.00500035 0.0040775  0.01428276 0.00834837 0.00789106\n",
            " 0.01828407 0.01035256 0.01074077 0.00239613 0.0053758  0.00493484\n",
            " 0.8784212  0.02240207 0.00329245 0.003312   0.00523762 0.8377225\n",
            " 0.87506753 0.01573989 0.00409613 0.00302048 0.6649556  0.71226734\n",
            " 0.02647958 0.8906207  0.01259533 0.00815064 0.7969128  0.00576516\n",
            " 0.0084322  0.00948339 0.02093204 0.85054445 0.00712354 0.00864011\n",
            " 0.0120987  0.00349178 0.00620095 0.01056968 0.00161847 0.01755168\n",
            " 0.02119571 0.02494465 0.00762427 0.00942408 0.85738724 0.8077801\n",
            " 0.00697097 0.02155776 0.01112911 0.00592061 0.00425338 0.00463667\n",
            " 0.00127653 0.01383231 0.0124488  0.0078069  0.01016335 0.00508947\n",
            " 0.00717433 0.8243358  0.01005293 0.72386456 0.02060966 0.00962936\n",
            " 0.01125477 0.00493615 0.00450883 0.01703852 0.00497528 0.7221712\n",
            " 0.00585294 0.01397126 0.00384688 0.0125909  0.00824713 0.00224396\n",
            " 0.00492553 0.00297729 0.00888023 0.00097683 0.0068777  0.00262317\n",
            " 0.01594445 0.8054265  0.01734587 0.00354247 0.00487335 0.03930203\n",
            " 0.01397756 0.01143695 0.0050351  0.00925015 0.00986779 0.00433292\n",
            " 0.00429244 0.00268629 0.00943485 0.0108858  0.904953   0.00669382\n",
            " 0.02592307 0.76346505 0.0153631  0.00244275 0.01364414 0.00522262\n",
            " 0.01985616 0.0074276  0.01255031 0.01146025 0.86066985 0.00836635\n",
            " 0.8801332  0.00181937 0.00881874 0.0029909  0.01369187 0.87406963\n",
            " 0.00754455 0.01414906 0.01983705 0.02601186 0.01432996 0.02443425\n",
            " 0.00376091 0.02625195 0.02094546 0.83434004 0.00206162 0.00372758\n",
            " 0.88812155 0.00631335 0.02270423 0.00931416 0.00307699 0.01641791\n",
            " 0.00772896 0.7496467  0.0164535  0.86094654 0.01050929 0.00910506\n",
            " 0.00550819 0.0136932  0.0450341  0.01112263 0.00658554 0.01150843\n",
            " 0.01423163 0.02435392 0.01378158 0.8445413  0.00477711 0.00415343\n",
            " 0.8300974  0.00465902 0.00536152 0.00194286 0.0067743  0.0064987\n",
            " 0.09642811 0.7062521  0.00495095 0.01426796 0.00596205 0.00943289\n",
            " 0.9094906  0.00713597 0.00668184 0.00751828 0.89123505 0.00900786\n",
            " 0.00914236 0.02537598 0.00610953 0.79149544 0.0250499  0.00299923\n",
            " 0.00779028 0.8241495  0.00097229 0.85989136 0.01079102 0.00820453\n",
            " 0.69142467 0.0031647  0.00341649 0.00635843 0.00392586 0.00489864\n",
            " 0.01062995 0.00345343 0.80787456 0.00555456 0.00892956 0.00627024\n",
            " 0.9157306  0.01747572 0.00693926 0.00294681 0.00715804 0.00801371\n",
            " 0.00531379 0.01566867 0.92839503 0.00497308 0.00227202 0.01378419\n",
            " 0.00470433 0.00299882 0.79911715 0.814877   0.70641893 0.00269266\n",
            " 0.0171759  0.8314634  0.0066548  0.00709984 0.01386717 0.0100657\n",
            " 0.01090154 0.00545628 0.01057787 0.00514251 0.01362726 0.0206147\n",
            " 0.82429427 0.00835235 0.01629999 0.00582052 0.88381594 0.03100087\n",
            " 0.02278055 0.01778718 0.01172666 0.00168313 0.00465914 0.00751194\n",
            " 0.00381316 0.00980857 0.01342518 0.01382356 0.00326221 0.00155582\n",
            " 0.00304162 0.01853828 0.00489372 0.92050487 0.00476962 0.0200474\n",
            " 0.0033267  0.00520512 0.9188553  0.00899269 0.00912232 0.00308388\n",
            " 0.0034884  0.0049319  0.01546681 0.00809427 0.00342412 0.0128949\n",
            " 0.01446229 0.01110325 0.02116493 0.0052213  0.01240588 0.02884988\n",
            " 0.90845567 0.01607795 0.0054033  0.00671243 0.01981844 0.00279138\n",
            " 0.00513838 0.0209936  0.00988932 0.02427755 0.01208716 0.00957579\n",
            " 0.01869777 0.00299359 0.00850024 0.01584157 0.00615656 0.00693587\n",
            " 0.00656626 0.00455152 0.00494498 0.02700578 0.01376121 0.05283154\n",
            " 0.00845788 0.01466194 0.00359384 0.00603061 0.01732777 0.00124846\n",
            " 0.00240783 0.03097668 0.0216343  0.00495583 0.00708767 0.0130613\n",
            " 0.01458947 0.00406266 0.02241905 0.9084552  0.00509977 0.008206\n",
            " 0.00417205 0.01065556 0.00501226 0.00949148 0.00686015 0.01518929\n",
            " 0.00933685 0.01219899 0.00474404 0.0018264  0.00408398 0.02355\n",
            " 0.00471807 0.00914355]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1374\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1359\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1360\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1452\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1453\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [500,1] vs. [140,1]\n\t [[{{node Equal}}]]",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-48dbf270a9e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m                             \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                             initial_state: val_state}\n\u001b[0;32m---> 32\u001b[0;31m                     \u001b[0mbatch_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_state\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                     \u001b[0mval_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Val acc: {:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 968\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1191\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1192\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1368\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1369\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1370\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1371\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1392\u001b[0m                     \u001b[0;34m'\\nsession_config.graph_options.rewrite_options.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1393\u001b[0m                     'disable_meta_optimizer = True')\n\u001b[0;32m-> 1394\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1396\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [500,1] vs. [140,1]\n\t [[node Equal (defined at <ipython-input-58-b38290192887>:2) ]]\n\nErrors may have originated from an input operation.\nInput Source operations connected to node Equal:\n labels (defined at <ipython-input-33-6e34d5c3fb38>:10)\n\nOriginal stack trace for 'Equal':\n  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 845, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n    self._context.run(self._callback, *self._args)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 451, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 434, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-58-b38290192887>\", line 2, in <module>\n    correct_pred = tf.equal(tf.cast(tf.round(predictions), tf.int32), labels_)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\", line 206, in wrapper\n    return target(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\", line 1729, in equal\n    return gen_math_ops.equal(x, y, name=name)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\", line 3230, in equal\n    name=name)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 750, in _apply_op_helper\n    attrs=attr_protos, op_def=op_def)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 3565, in _create_op_internal\n    op_def=op_def)\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 2045, in __init__\n    self._traceback = tf_stack.extract_stack_for_node(self._c_op)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVSoNOUnRVxu"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40kGoPR0RVxu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "41c40527-cd6e-4123-b32f-6145b75028ec"
      },
      "source": [
        "test_acc = []\n",
        "with tf.compat.v1.Session(graph=graph) as sess:\n",
        "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
        "    test_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
        "    for ii, (x, y) in enumerate(get_batches(test_x, test_y, batch_size), 1):\n",
        "        feed = {inputs_: x,\n",
        "                labels_: y[:, None],\n",
        "                keep_prob: 1,\n",
        "                initial_state: test_state}\n",
        "        batch_acc, test_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
        "        test_acc.append(batch_acc)\n",
        "    print(\"Test accuracy: {:.3f}\".format(np.mean(test_acc)))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-05777b935a77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'checkpoints'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mtest_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mii\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1289\u001b[0m       \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msave_path\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can't load save_path when it is None.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m     \u001b[0mcheckpoint_prefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Can't load save_path when it is None."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qVwAXFoRVxy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}